{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7mr-YkZA6nd9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://github.com/bipulshahi/Dataset/raw/refs/heads/main/Advertising.csv',\n",
        "                 index_col = 0)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZyRueriq650e",
        "outputId": "8e27943a-2205-407b-ef5e-16614cb5182f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      TV  radio  newspaper  sales\n",
              "1  230.1   37.8       69.2   22.1\n",
              "2   44.5   39.3       45.1   10.4\n",
              "3   17.2   45.9       69.3    9.3\n",
              "4  151.5   41.3       58.5   18.5\n",
              "5  180.8   10.8       58.4   12.9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b8e015b-60d2-4491-9b54-2d0d67d97887\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TV</th>\n",
              "      <th>radio</th>\n",
              "      <th>newspaper</th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230.1</td>\n",
              "      <td>37.8</td>\n",
              "      <td>69.2</td>\n",
              "      <td>22.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44.5</td>\n",
              "      <td>39.3</td>\n",
              "      <td>45.1</td>\n",
              "      <td>10.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17.2</td>\n",
              "      <td>45.9</td>\n",
              "      <td>69.3</td>\n",
              "      <td>9.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>151.5</td>\n",
              "      <td>41.3</td>\n",
              "      <td>58.5</td>\n",
              "      <td>18.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>180.8</td>\n",
              "      <td>10.8</td>\n",
              "      <td>58.4</td>\n",
              "      <td>12.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b8e015b-60d2-4491-9b54-2d0d67d97887')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b8e015b-60d2-4491-9b54-2d0d67d97887 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b8e015b-60d2-4491-9b54-2d0d67d97887');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4399270f-47e6-43fb-bd49-cd74813bb276\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4399270f-47e6-43fb-bd49-cd74813bb276')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4399270f-47e6-43fb-bd49-cd74813bb276 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 200,\n  \"fields\": [\n    {\n      \"column\": \"TV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85.8542363149081,\n        \"min\": 0.7,\n        \"max\": 296.4,\n        \"num_unique_values\": 190,\n        \"samples\": [\n          287.6,\n          286.0,\n          78.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"radio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.846809176168723,\n        \"min\": 0.0,\n        \"max\": 49.6,\n        \"num_unique_values\": 167,\n        \"samples\": [\n          8.2,\n          36.9,\n          44.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"newspaper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.778620838522833,\n        \"min\": 0.3,\n        \"max\": 114.0,\n        \"num_unique_values\": 172,\n        \"samples\": [\n          22.3,\n          5.7,\n          17.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sales\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.217456565710477,\n        \"min\": 1.6,\n        \"max\": 27.0,\n        \"num_unique_values\": 121,\n        \"samples\": [\n          11.4,\n          21.2,\n          12.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns = 'sales')\n",
        "y = df['sales']"
      ],
      "metadata": {
        "id": "UtCifep168o1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w0 = 1\n",
        "w1 = 2\n",
        "w2 = 3\n",
        "w3 = 2\n",
        "\n",
        "yh = w0 + w1 * X.TV + w2 * X.radio + w3 * X.newspaper"
      ],
      "metadata": {
        "id": "y-Ibpef47WEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w0 = 1\n",
        "w1 = 2\n",
        "w2 = 3\n",
        "w3 = 2\n",
        "\n",
        "for i in range(0,1000):\n",
        "    yh = w0 + w1 * X.TV + w2 * X.radio + w3 * X.newspaper\n",
        "\n",
        "    dew0 = -2 * ((y - yh)).mean()\n",
        "    dew1 = -2 * ((y - yh) * X.TV).mean()\n",
        "    dew2 = -2 * ((y - yh) * X.radio).mean()\n",
        "    dew3 = -2 * ((y - yh) * X.newspaper).mean()\n",
        "\n",
        "    lr = 0.00001\n",
        "\n",
        "    w0 = w0 - lr * dew0\n",
        "    w1 = w1 - lr * dew1\n",
        "    w2 = w2 - lr * dew2\n",
        "    w3 = w3 - lr * dew3\n",
        "\n",
        "    error = ((y - yh)**2).mean()\n",
        "    print(i , error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU_jqFC68BBQ",
        "outputId": "1bf4f1de-ff15-4250-e73a-a12e38a870ea"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 204218.34145\n",
            "1 37010.858512662446\n",
            "2 10485.501210091585\n",
            "3 6161.542970334401\n",
            "4 5344.855901772746\n",
            "5 5085.729328973425\n",
            "6 4918.6241322339965\n",
            "7 4769.959987570218\n",
            "8 4628.004161292239\n",
            "9 4490.786162378795\n",
            "10 4357.879550673034\n",
            "11 4229.105145379921\n",
            "12 4104.326301608049\n",
            "13 3983.4164979304082\n",
            "14 3866.2541148193577\n",
            "15 3752.721506667993\n",
            "16 3642.704754538022\n",
            "17 3536.0935294906903\n",
            "18 3432.7809764429076\n",
            "19 3332.663604242222\n",
            "20 3235.6411796094285\n",
            "21 3141.6166244869037\n",
            "22 3050.4959166316653\n",
            "23 2962.187993342451\n",
            "24 2876.604658220727\n",
            "25 2793.6604908697946\n",
            "26 2713.2727594393855\n",
            "27 2635.3613359260607\n",
            "28 2559.8486141425788\n",
            "29 2486.659430272128\n",
            "30 2415.7209859259515\n",
            "31 2346.9627736254956\n",
            "32 2280.316504632669\n",
            "33 2215.716039054215\n",
            "34 2153.09731814854\n",
            "35 2092.3982987655945\n",
            "36 2033.5588898525748\n",
            "37 1976.5208909603662\n",
            "38 1921.2279326876626\n",
            "39 1867.6254190017114\n",
            "40 1815.6604713765412\n",
            "41 1765.2818746914008\n",
            "42 1716.4400248339434\n",
            "43 1669.0868779544305\n",
            "44 1623.17590131893\n",
            "45 1578.6620257111217\n",
            "46 1535.5015993339098\n",
            "47 1493.6523431635758\n",
            "48 1453.0733077107043\n",
            "49 1413.724831143549\n",
            "50 1375.5684987309028\n",
            "51 1338.5671035628945\n",
            "52 1302.6846085094433\n",
            "53 1267.8861093773617\n",
            "54 1234.137799228346\n",
            "55 1201.4069338212635\n",
            "56 1169.6617981433105\n",
            "57 1138.8716739957297\n",
            "58 1109.0068086008532\n",
            "59 1080.038384198288\n",
            "60 1051.9384885990762\n",
            "61 1024.6800866676376\n",
            "62 998.2369927022623\n",
            "63 972.5838436858371\n",
            "64 947.6960733793816\n",
            "65 923.5498872318384\n",
            "66 900.1222380803933\n",
            "67 877.3908026164135\n",
            "68 855.3339585928817\n",
            "69 833.9307627499572\n",
            "70 813.1609294360342\n",
            "71 793.0048099023837\n",
            "72 773.4433722501501\n",
            "73 754.4581820091495\n",
            "74 736.0313833285556\n",
            "75 718.145680760197\n",
            "76 700.784321615788\n",
            "77 683.9310788800092\n",
            "78 667.5702346619213\n",
            "79 651.6865641677499\n",
            "80 636.2653201786109\n",
            "81 621.2922180172646\n",
            "82 606.753420988492\n",
            "83 592.6355262781639\n",
            "84 578.9255512965526\n",
            "85 565.6109204518867\n",
            "86 552.6794523405915\n",
            "87 540.1193473410835\n",
            "88 527.9191755984049\n",
            "89 516.0678653873816\n",
            "90 504.5546918423759\n",
            "91 493.36926604208355\n",
            "92 482.5015244381871\n",
            "93 471.9417186170306\n",
            "94 461.6804053838215\n",
            "95 451.7084371591971\n",
            "96 442.0169526783126\n",
            "97 432.59736798291823\n",
            "98 423.44136769719364\n",
            "99 414.5408965783981\n",
            "100 405.888151333676\n",
            "101 397.4755726946333\n",
            "102 389.29583774156026\n",
            "103 381.34185246943554\n",
            "104 373.6067445880927\n",
            "105 366.08385654917083\n",
            "106 358.7667387927031\n",
            "107 351.6491432064229\n",
            "108 344.7250167910848\n",
            "109 337.98849552530913\n",
            "110 331.4338984236628\n",
            "111 325.0557217818882\n",
            "112 318.8486336033829\n",
            "113 312.80746820121936\n",
            "114 306.92722097017344\n",
            "115 301.2030433234058\n",
            "116 295.6302377886055\n",
            "117 290.2042532585754\n",
            "118 284.92068039138996\n",
            "119 279.77524715541296\n",
            "120 274.7638145146136\n",
            "121 269.8823722497563\n",
            "122 265.1270349111866\n",
            "123 260.4940378990652\n",
            "124 255.9797336670341\n",
            "125 251.58058804542793\n",
            "126 247.29317668026073\n",
            "127 243.11418158434375\n",
            "128 239.04038779699857\n",
            "129 235.0686801489462\n",
            "130 231.19604012905643\n",
            "131 227.41954284974955\n",
            "132 223.73635410794225\n",
            "133 220.1437275385263\n",
            "134 216.63900185746544\n",
            "135 213.2195981916874\n",
            "136 209.88301749303565\n",
            "137 206.62683803363262\n",
            "138 203.44871298009014\n",
            "139 200.34636804408206\n",
            "140 197.31759920687455\n",
            "141 194.3602705154822\n",
            "142 191.47231194819543\n",
            "143 188.65171734729196\n",
            "144 185.89654241681666\n",
            "145 183.20490278338025\n",
            "146 180.57497211798992\n",
            "147 178.00498031699095\n",
            "148 175.4932117402564\n",
            "149 173.03800350482084\n",
            "150 170.63774383221207\n",
            "151 168.2908704477895\n",
            "152 165.9958690304502\n",
            "153 163.75127171111592\n",
            "154 161.55565561846538\n",
            "155 159.4076414704218\n",
            "156 157.30589220995648\n",
            "157 155.2491116838103\n",
            "158 153.23604336278274\n",
            "159 151.26546910227836\n",
            "160 149.33620794184262\n",
            "161 147.44711494245917\n",
            "162 145.59708006041893\n",
            "163 143.78502705660893\n",
            "164 142.00991244010558\n",
            "165 140.27072444499126\n",
            "166 138.56648203934864\n",
            "167 136.89623396541808\n",
            "168 135.25905780993745\n",
            "169 133.65405910371362\n",
            "170 132.08037044950433\n",
            "171 130.53715067731943\n",
            "172 129.0235840262777\n",
            "173 127.53887935218252\n",
            "174 126.0822693600073\n",
            "175 124.6530098605048\n",
            "176 123.2503790501819\n",
            "177 121.87367681390334\n",
            "178 120.5222240494115\n",
            "179 119.19536201307284\n",
            "180 117.89245168618177\n",
            "181 116.61287316117516\n",
            "182 115.3560250471298\n",
            "183 114.12132389393635\n",
            "184 112.9082036345614\n",
            "185 111.71611504482749\n",
            "186 110.54452522016064\n",
            "187 109.39291706876976\n",
            "188 108.2607888207419\n",
            "189 107.14765355255089\n",
            "190 106.05303872649547\n",
            "191 104.97648574459534\n",
            "192 103.91754951649136\n",
            "193 102.87579804090778\n",
            "194 101.85081200025056\n",
            "195 100.84218436792742\n",
            "196 99.84952002798964\n",
            "197 98.87243540670735\n",
            "198 97.91055811570305\n",
            "199 96.96352660627916\n",
            "200 96.03098983458713\n",
            "201 95.11260693729757\n",
            "202 94.20804691744\n",
            "203 93.3169883400926\n",
            "204 92.4391190376118\n",
            "205 91.57413582410152\n",
            "206 90.72174421883133\n",
            "207 89.88165817832152\n",
            "208 89.05359983682287\n",
            "209 88.23729925492664\n",
            "210 87.43249417604858\n",
            "211 86.63892979054027\n",
            "212 85.85635850718646\n",
            "213 85.08453973185686\n",
            "214 84.32323965308719\n",
            "215 83.57223103437101\n",
            "216 82.83129301295185\n",
            "217 82.10021090491058\n",
            "218 81.37877601635034\n",
            "219 80.66678546048698\n",
            "220 79.96404198045946\n",
            "221 79.27035377768006\n",
            "222 78.58553434555029\n",
            "223 77.90940230837391\n",
            "224 77.24178126530315\n",
            "225 76.58249963916025\n",
            "226 75.93139052998087\n",
            "227 75.28829157313079\n",
            "228 74.65304480185239\n",
            "229 74.02549651410116\n",
            "230 73.40549714353791\n",
            "231 72.79290113454546\n",
            "232 72.18756682114376\n",
            "233 71.58935630968082\n",
            "234 70.99813536518035\n",
            "235 70.41377330123174\n",
            "236 69.83614287331065\n",
            "237 69.2651201754227\n",
            "238 68.70058453996542\n",
            "239 68.14241844070787\n",
            "240 67.59050739878946\n",
            "241 67.04473989164346\n",
            "242 66.50500726475316\n",
            "243 65.9712036461517\n",
            "244 65.44322586357946\n",
            "245 64.92097336421556\n",
            "246 64.40434813690241\n",
            "247 63.89325463678538\n",
            "248 63.38759971229131\n",
            "249 62.887292534373\n",
            "250 62.39224452794784\n",
            "251 61.902369305462344\n",
            "252 61.417582602515495\n",
            "253 60.937802215476275\n",
            "254 60.46294794103313\n",
            "255 59.992941517614256\n",
            "256 59.527706568620445\n",
            "257 59.06716854741333\n",
            "258 58.611254684004145\n",
            "259 58.159893933389576\n",
            "260 57.713016925483004\n",
            "261 57.27055591659128\n",
            "262 56.8324447423884\n",
            "263 56.39861877233914\n",
            "264 55.96901486552746\n",
            "265 55.54357132784525\n",
            "266 55.12222787049912\n",
            "267 54.70492556979378\n",
            "268 54.29160682815207\n",
            "269 53.8822153363328\n",
            "270 53.476696036809074\n",
            "271 53.07499508827046\n",
            "272 52.67705983121426\n",
            "273 52.282838754591246\n",
            "274 51.89228146347334\n",
            "275 51.50533864771091\n",
            "276 51.12196205154894\n",
            "277 50.74210444417197\n",
            "278 50.36571959114868\n",
            "279 49.992762226748255\n",
            "280 49.62318802710093\n",
            "281 49.25695358417653\n",
            "282 48.894016380555456\n",
            "283 48.534334764967205\n",
            "284 48.17786792857255\n",
            "285 47.82457588196623\n",
            "286 47.47441943287733\n",
            "287 47.12736016454607\n",
            "288 46.78336041475528\n",
            "289 46.442383255496786\n",
            "290 46.104392473252304\n",
            "291 45.76935254987006\n",
            "292 45.43722864401834\n",
            "293 45.10798657319826\n",
            "294 44.78159279629787\n",
            "295 44.45801439667122\n",
            "296 44.13721906572566\n",
            "297 43.8191750870018\n",
            "298 43.50385132073061\n",
            "299 43.191217188852825\n",
            "300 42.881242660486514\n",
            "301 42.5738982378285\n",
            "302 42.269154942476376\n",
            "303 41.96698430215807\n",
            "304 41.667358337856086\n",
            "305 41.37024955131435\n",
            "306 41.07563091291577\n",
            "307 40.783475849918794\n",
            "308 40.493758235042165\n",
            "309 40.206452375386725\n",
            "310 39.92153300168412\n",
            "311 39.63897525786198\n",
            "312 39.358754690916065\n",
            "313 39.0808472410796\n",
            "314 38.80522923228081\n",
            "315 38.53187736287961\n",
            "316 38.26076869667488\n",
            "317 37.99188065417382\n",
            "318 37.72519100411563\n",
            "319 37.460677855241194\n",
            "320 37.19831964830155\n",
            "321 36.93809514829759\n",
            "322 36.67998343694383\n",
            "323 36.42396390534963\n",
            "324 36.17001624691072\n",
            "325 35.91812045040487\n",
            "326 35.6682567932854\n",
            "327 35.42040583516633\n",
            "328 35.17454841149331\n",
            "329 34.93066562739472\n",
            "330 34.68873885170721\n",
            "331 34.44874971117063\n",
            "332 34.21068008478681\n",
            "333 33.97451209833744\n",
            "334 33.74022811905603\n",
            "335 33.50781075044931\n",
            "336 33.27724282726342\n",
            "337 33.04850741059061\n",
            "338 32.82158778311197\n",
            "339 32.5964674444722\n",
            "340 32.37313010678225\n",
            "341 32.151559690246145\n",
            "342 31.931740318908005\n",
            "343 31.713656316515657\n",
            "344 31.497292202497373\n",
            "345 31.282632688048267\n",
            "346 31.06966267232295\n",
            "347 30.858367238731333\n",
            "348 30.648731651334423\n",
            "349 30.440741351336925\n",
            "350 30.234381953674095\n",
            "351 30.029639243689573\n",
            "352 29.826499173901738\n",
            "353 29.624947860855883\n",
            "354 29.424971582059424\n",
            "355 29.226556772997974\n",
            "356 29.02969002422955\n",
            "357 28.834358078554768\n",
            "358 28.640547828260623\n",
            "359 28.448246312435785\n",
            "360 28.257440714355134\n",
            "361 28.06811835893157\n",
            "362 27.880266710233027\n",
            "363 27.693873369062803\n",
            "364 27.50892607060126\n",
            "365 27.32541268210718\n",
            "366 27.14332120067688\n",
            "367 26.962639751059406\n",
            "368 26.783356583526306\n",
            "369 26.60546007179409\n",
            "370 26.42893871099808\n",
            "371 26.253781115715945\n",
            "372 26.079976018039734\n",
            "373 25.907512265694503\n",
            "374 25.736378820202777\n",
            "375 25.566564755092976\n",
            "376 25.398059254150912\n",
            "377 25.230851609712772\n",
            "378 25.064931220998687\n",
            "379 24.90028759248552\n",
            "380 24.736910332317745\n",
            "381 24.574789150755404\n",
            "382 24.413913858658006\n",
            "383 24.25427436600336\n",
            "384 24.095860680440328\n",
            "385 23.9386629058745\n",
            "386 23.782671241085918\n",
            "387 23.627875978377855\n",
            "388 23.474267502255834\n",
            "389 23.321836288135966\n",
            "390 23.170572901081805\n",
            "391 23.02046799456897\n",
            "392 22.87151230927658\n",
            "393 22.723696671904978\n",
            "394 22.577011994018818\n",
            "395 22.43144927091491\n",
            "396 22.286999580514056\n",
            "397 22.143654082276306\n",
            "398 22.001404016138885\n",
            "399 21.860240701476187\n",
            "400 21.72015553608134\n",
            "401 21.58113999516853\n",
            "402 21.44318563039571\n",
            "403 21.306284068907054\n",
            "404 21.170427012394615\n",
            "405 21.035606236178673\n",
            "406 20.901813588306275\n",
            "407 20.76904098866747\n",
            "408 20.637280428128737\n",
            "409 20.506523967683236\n",
            "410 20.37676373761726\n",
            "411 20.247991936692653\n",
            "412 20.120200831344622\n",
            "413 19.99338275489464\n",
            "414 19.867530106777902\n",
            "415 19.742635351785182\n",
            "416 19.618691019318423\n",
            "417 19.49568970265996\n",
            "418 19.373624058254872\n",
            "419 19.25248680500618\n",
            "420 19.13227072358251\n",
            "421 19.012968655738025\n",
            "422 18.894573503644118\n",
            "423 18.777078229232743\n",
            "424 18.660475853551013\n",
            "425 18.544759456126776\n",
            "426 18.429922174344906\n",
            "427 18.315957202834028\n",
            "428 18.2028577928635\n",
            "429 18.090617251750228\n",
            "430 17.979228942275245\n",
            "431 17.86868628210974\n",
            "432 17.758982743250275\n",
            "433 17.650111851463013\n",
            "434 17.54206718573676\n",
            "435 17.434842377744538\n",
            "436 17.328431111313552\n",
            "437 17.222827121903315\n",
            "438 17.11802419609175\n",
            "439 17.014016171069056\n",
            "440 16.91079693413925\n",
            "441 16.808360422229054\n",
            "442 16.70670062140408\n",
            "443 16.60581156639213\n",
            "444 16.505687340113372\n",
            "445 16.40632207321732\n",
            "446 16.30770994362645\n",
            "447 16.209845176086223\n",
            "448 16.112722041721526\n",
            "449 16.016334857599226\n",
            "450 15.920677986296777\n",
            "451 15.825745835476814\n",
            "452 15.731532857467457\n",
            "453 15.638033548848323\n",
            "454 15.54524245004207\n",
            "455 15.453154144911373\n",
            "456 15.361763260361194\n",
            "457 15.271064465946274\n",
            "458 15.181052473483698\n",
            "459 15.091722036670449\n",
            "460 15.003067950705857\n",
            "461 14.9150850519188\n",
            "462 14.827768217399642\n",
            "463 14.741112364636695\n",
            "464 14.655112451157256\n",
            "465 14.569763474172987\n",
            "466 14.48506047022967\n",
            "467 14.400998514861136\n",
            "468 14.317572722247473\n",
            "469 14.234778244877152\n",
            "470 14.152610273213277\n",
            "471 14.071064035363696\n",
            "472 13.990134796754976\n",
            "473 13.909817859810175\n",
            "474 13.83010856363029\n",
            "475 13.751002283679359\n",
            "476 13.67249443147314\n",
            "477 13.594580454271286\n",
            "478 13.517255834772984\n",
            "479 13.440516090815963\n",
            "480 13.364356775078809\n",
            "481 13.28877347478661\n",
            "482 13.21376181141973\n",
            "483 13.139317440425785\n",
            "484 13.065436050934718\n",
            "485 12.992113365476904\n",
            "486 12.919345139704257\n",
            "487 12.84712716211429\n",
            "488 12.775455253777057\n",
            "489 12.704325268064977\n",
            "490 12.633733090385421\n",
            "491 12.563674637916083\n",
            "492 12.494145859343064\n",
            "493 12.425142734601614\n",
            "494 12.356661274619523\n",
            "495 12.288697521063078\n",
            "496 12.221247546085584\n",
            "497 12.154307452078381\n",
            "498 12.087873371424372\n",
            "499 12.021941466253905\n",
            "500 11.956507928203132\n",
            "501 11.891568978174691\n",
            "502 11.827120866100723\n",
            "503 11.763159870708172\n",
            "504 11.699682299286362\n",
            "505 11.636684487456796\n",
            "506 11.574162798945132\n",
            "507 11.512113625355353\n",
            "508 11.450533385946057\n",
            "509 11.38941852740885\n",
            "510 11.32876552364881\n",
            "511 11.26857087556702\n",
            "512 11.208831110845086\n",
            "513 11.149542783731688\n",
            "514 11.090702474831073\n",
            "515 11.032306790893472\n",
            "516 10.974352364607482\n",
            "517 10.916835854394286\n",
            "518 10.859753944203753\n",
            "519 10.803103343312419\n",
            "520 10.746880786123201\n",
            "521 10.691083031967015\n",
            "522 10.635706864906055\n",
            "523 10.58074909353892\n",
            "524 10.526206550807387\n",
            "525 10.472076093804963\n",
            "526 10.418354603587073\n",
            "527 10.365038984982949\n",
            "528 10.31212616640912\n",
            "529 10.25961309968461\n",
            "530 10.207496759847634\n",
            "531 10.155774144973986\n",
            "532 10.104442275996934\n",
            "533 10.053498196528702\n",
            "534 10.002938972683456\n",
            "535 9.952761692901827\n",
            "536 9.902963467776948\n",
            "537 9.853541429881934\n",
            "538 9.80449273359887\n",
            "539 9.755814554949222\n",
            "540 9.70750409142569\n",
            "541 9.659558561825493\n",
            "542 9.611975206085027\n",
            "543 9.564751285115959\n",
            "544 9.517884080642634\n",
            "545 9.4713708950409\n",
            "546 9.425209051178237\n",
            "547 9.379395892255223\n",
            "548 9.333928781648344\n",
            "549 9.288805102754061\n",
            "550 9.244022258834212\n",
            "551 9.199577672862642\n",
            "552 9.155468787373156\n",
            "553 9.111693064308664\n",
            "554 9.068247984871588\n",
            "555 9.025131049375505\n",
            "556 8.98233977709799\n",
            "557 8.939871706134639\n",
            "558 8.89772439325434\n",
            "559 8.855895413755647\n",
            "560 8.814382361324384\n",
            "561 8.773182847892349\n",
            "562 8.732294503497211\n",
            "563 8.691714976143505\n",
            "564 8.651441931664746\n",
            "565 8.611473053586684\n",
            "566 8.571806042991632\n",
            "567 8.532438618383894\n",
            "568 8.493368515556257\n",
            "569 8.454593487457581\n",
            "570 8.41611130406143\n",
            "571 8.377919752235732\n",
            "572 8.340016635613527\n",
            "573 8.302399774464702\n",
            "574 8.265067005568765\n",
            "575 8.228016182088629\n",
            "576 8.19124517344539\n",
            "577 8.154751865194115\n",
            "578 8.118534158900582\n",
            "579 8.082589972019035\n",
            "580 8.046917237770872\n",
            "581 8.011513905024314\n",
            "582 7.976377938174994\n",
            "583 7.941507317027532\n",
            "584 7.906900036677991\n",
            "585 7.872554107397281\n",
            "586 7.838467554515502\n",
            "587 7.804638418307147\n",
            "588 7.771064753877232\n",
            "589 7.737744631048333\n",
            "590 7.704676134248472\n",
            "591 7.671857362399896\n",
            "592 7.639286428808742\n",
            "593 7.606961461055526\n",
            "594 7.574880600886531\n",
            "595 7.543042004105995\n",
            "596 7.51144384046918\n",
            "597 7.480084293576244\n",
            "598 7.4489615607669615\n",
            "599 7.418073853016233\n",
            "600 7.387419394830448\n",
            "601 7.356996424144605\n",
            "602 7.326803192220268\n",
            "603 7.29683796354429\n",
            "604 7.267099015728338\n",
            "605 7.237584639409183\n",
            "606 7.208293138149763\n",
            "607 7.179222828341028\n",
            "608 7.150372039104513\n",
            "609 7.121739112195701\n",
            "610 7.093322401908091\n",
            "611 7.0651202749780415\n",
            "612 7.03713111049033\n",
            "613 7.009353299784449\n",
            "614 6.981785246361608\n",
            "615 6.954425365792479\n",
            "616 6.9272720856256225\n",
            "617 6.900323845296641\n",
            "618 6.873579096038018\n",
            "619 6.847036300789656\n",
            "620 6.820693934110102\n",
            "621 6.794550482088448\n",
            "622 6.768604442256919\n",
            "623 6.742854323504125\n",
            "624 6.7172986459889765\n",
            "625 6.691935941055264\n",
            "626 6.666764751146901\n",
            "627 6.641783629723791\n",
            "628 6.61699114117837\n",
            "629 6.592385860752765\n",
            "630 6.567966374456603\n",
            "631 6.543731278985426\n",
            "632 6.519679181639766\n",
            "633 6.4958087002448055\n",
            "634 6.47211846307066\n",
            "635 6.4486071087533015\n",
            "636 6.425273286216026\n",
            "637 6.402115654591569\n",
            "638 6.379132883144816\n",
            "639 6.356323651196069\n",
            "640 6.3336866480449245\n",
            "641 6.311220572894729\n",
            "642 6.288924134777606\n",
            "643 6.266796052480056\n",
            "644 6.244835054469132\n",
            "645 6.223039878819162\n",
            "646 6.201409273139042\n",
            "647 6.179941994500084\n",
            "648 6.158636809364404\n",
            "649 6.137492493513866\n",
            "650 6.116507831979554\n",
            "651 6.095681618971804\n",
            "652 6.075012657810738\n",
            "653 6.054499760857352\n",
            "654 6.034141749445116\n",
            "655 6.0139374538121055\n",
            "656 5.993885713033621\n",
            "657 5.973985374955366\n",
            "658 5.954235296127085\n",
            "659 5.934634341736744\n",
            "660 5.915181385545191\n",
            "661 5.895875309821309\n",
            "662 5.87671500527769\n",
            "663 5.85769937100676\n",
            "664 5.838827314417411\n",
            "665 5.820097751172129\n",
            "666 5.801509605124551\n",
            "667 5.783061808257553\n",
            "668 5.764753300621769\n",
            "669 5.7465830302746\n",
            "670 5.7285499532196535\n",
            "671 5.710653033346696\n",
            "672 5.692891242372002\n",
            "673 5.675263559779202\n",
            "674 5.657768972760548\n",
            "675 5.640406476158654\n",
            "676 5.623175072408642\n",
            "677 5.606073771480761\n",
            "678 5.589101590823423\n",
            "679 5.572257555306675\n",
            "680 5.555540697166094\n",
            "681 5.538950055947124\n",
            "682 5.522484678449814\n",
            "683 5.506143618673994\n",
            "684 5.489925937764845\n",
            "685 5.473830703958907\n",
            "686 5.457856992530469\n",
            "687 5.442003885738398\n",
            "688 5.426270472773336\n",
            "689 5.410655849705315\n",
            "690 5.395159119431777\n",
            "691 5.379779391625968\n",
            "692 5.364515782685738\n",
            "693 5.34936741568272\n",
            "694 5.334333420311903\n",
            "695 5.319412932841572\n",
            "696 5.304605096063645\n",
            "697 5.289909059244374\n",
            "698 5.2753239780754235\n",
            "699 5.26084901462532\n",
            "700 5.2464833372912585\n",
            "701 5.232226120751302\n",
            "702 5.2180765459169\n",
            "703 5.204033799885812\n",
            "704 5.190097075895349\n",
            "705 5.176265573275998\n",
            "706 5.162538497405376\n",
            "707 5.148915059662543\n",
            "708 5.135394477382662\n",
            "709 5.121975973812002\n",
            "710 5.108658778063267\n",
            "711 5.095442125071287\n",
            "712 5.0823252555490255\n",
            "713 5.069307415943928\n",
            "714 5.056387858394599\n",
            "715 5.043565840687802\n",
            "716 5.030840626215798\n",
            "717 5.018211483933993\n",
            "718 5.005677688318907\n",
            "719 4.993238519326476\n",
            "720 4.980893262350647\n",
            "721 4.9686412081823015\n",
            "722 4.956481652968488\n",
            "723 4.944413898171961\n",
            "724 4.932437250531016\n",
            "725 4.92055102201965\n",
            "726 4.908754529807998\n",
            "727 4.897047096223097\n",
            "728 4.885428048709917\n",
            "729 4.873896719792706\n",
            "730 4.862452447036625\n",
            "731 4.851094573009663\n",
            "732 4.839822445244855\n",
            "733 4.828635416202775\n",
            "734 4.817532843234309\n",
            "735 4.806514088543723\n",
            "736 4.795578519152004\n",
            "737 4.784725506860471\n",
            "738 4.773954428214665\n",
            "739 4.763264664468527\n",
            "740 4.752655601548819\n",
            "741 4.742126630019836\n",
            "742 4.731677145048379\n",
            "743 4.721306546368986\n",
            "744 4.711014238249432\n",
            "745 4.700799629456494\n",
            "746 4.69066213322196\n",
            "747 4.6806011672089145\n",
            "748 4.670616153478261\n",
            "749 4.660706518455511\n",
            "750 4.650871692897811\n",
            "751 4.64111111186123\n",
            "752 4.631424214668295\n",
            "753 4.621810444875755\n",
            "754 4.61226925024261\n",
            "755 4.602800082698369\n",
            "756 4.593402398311554\n",
            "757 4.584075657258427\n",
            "758 4.574819323791981\n",
            "759 4.565632866211142\n",
            "760 4.556515756830209\n",
            "761 4.54746747194853\n",
            "762 4.538487491820406\n",
            "763 4.529575300625213\n",
            "764 4.520730386437772\n",
            "765 4.5119522411989115\n",
            "766 4.503240360686277\n",
            "767 4.494594244485359\n",
            "768 4.486013395960723\n",
            "769 4.477497322227473\n",
            "770 4.469045534122924\n",
            "771 4.4606575461785\n",
            "772 4.452332876591814\n",
            "773 4.444071047199001\n",
            "774 4.435871583447225\n",
            "775 4.427734014367409\n",
            "776 4.419657872547171\n",
            "777 4.411642694103969\n",
            "778 4.403688018658423\n",
            "779 4.39579338930788\n",
            "780 4.387958352600146\n",
            "781 4.380182458507424\n",
            "782 4.372465260400461\n",
            "783 4.364806315022874\n",
            "784 4.357205182465678\n",
            "785 4.349661426142009\n",
            "786 4.34217461276203\n",
            "787 4.3347443123080405\n",
            "788 4.327370098009746\n",
            "789 4.3200515463197595\n",
            "790 4.312788236889234\n",
            "791 4.305579752543725\n",
            "792 4.29842567925921\n",
            "793 4.291325606138297\n",
            "794 4.284279125386615\n",
            "795 4.277285832289371\n",
            "796 4.270345325188101\n",
            "797 4.263457205457586\n",
            "798 4.256621077482942\n",
            "799 4.249836548636887\n",
            "800 4.243103229257184\n",
            "801 4.236420732624237\n",
            "802 4.229788674938878\n",
            "803 4.223206675300312\n",
            "804 4.216674355684217\n",
            "805 4.210191340921031\n",
            "806 4.203757258674396\n",
            "807 4.197371739419749\n",
            "808 4.191034416423096\n",
            "809 4.18474492571994\n",
            "810 4.178502906094353\n",
            "811 4.172307999058236\n",
            "812 4.166159848830703\n",
            "813 4.160058102317645\n",
            "814 4.154002409091442\n",
            "815 4.147992421370812\n",
            "816 4.142027794000846\n",
            "817 4.136108184433152\n",
            "818 4.130233252706192\n",
            "819 4.1244026614257265\n",
            "820 4.118616075745441\n",
            "821 4.112873163347699\n",
            "822 4.107173594424442\n",
            "823 4.101517041658246\n",
            "824 4.095903180203504\n",
            "825 4.090331687667762\n",
            "826 4.084802244093196\n",
            "827 4.079314531938221\n",
            "828 4.073868236059248\n",
            "829 4.068463043692572\n",
            "830 4.0630986444363995\n",
            "831 4.057774730233013\n",
            "832 4.05249099535107\n",
            "833 4.047247136368028\n",
            "834 4.042042852152717\n",
            "835 4.036877843848031\n",
            "836 4.031751814853754\n",
            "837 4.02666447080952\n",
            "838 4.021615519577893\n",
            "839 4.016604671227584\n",
            "840 4.011631638016787\n",
            "841 4.00669613437665\n",
            "842 4.001797876894858\n",
            "843 3.9969365842993487\n",
            "844 3.9921119774421583\n",
            "845 3.9873237792833676\n",
            "846 3.9825717148751925\n",
            "847 3.977855511346179\n",
            "848 3.9731748978855235\n",
            "849 3.9685296057275163\n",
            "850 3.963919368136091\n",
            "851 3.9593439203895016\n",
            "852 3.954802999765105\n",
            "853 3.9502963455242734\n",
            "854 3.9458236988974007\n",
            "855 3.9413848030690417\n",
            "856 3.9369794031631513\n",
            "857 3.9326072462284345\n",
            "858 3.92826808122382\n",
            "859 3.923961659004027\n",
            "860 3.919687732305247\n",
            "861 3.9154460557309476\n",
            "862 3.9112363857377574\n",
            "863 3.9070584806214783\n",
            "864 3.9029121005031957\n",
            "865 3.898797007315492\n",
            "866 3.894712964788771\n",
            "867 3.890659738437677\n",
            "868 3.8866370955476204\n",
            "869 3.8826448051614126\n",
            "870 3.87868263806598\n",
            "871 3.8747503667792116\n",
            "872 3.8708477655368694\n",
            "873 3.8669746102796285\n",
            "874 3.863130678640192\n",
            "875 3.859315749930523\n",
            "876 3.855529605129156\n",
            "877 3.8517720268686135\n",
            "878 3.848042799422915\n",
            "879 3.844341708695182\n",
            "880 3.840668542205334\n",
            "881 3.8370230890778827\n",
            "882 3.833405140029809\n",
            "883 3.8298144873585396\n",
            "884 3.8262509249300116\n",
            "885 3.822714248166828\n",
            "886 3.819204254036502\n",
            "887 3.8157207410397898\n",
            "888 3.812263509199113\n",
            "889 3.8088323600470666\n",
            "890 3.8054270966150114\n",
            "891 3.8020475234217628\n",
            "892 3.798693446462353\n",
            "893 3.7953646731968824\n",
            "894 3.7920610125394587\n",
            "895 3.788782274847215\n",
            "896 3.785528271909411\n",
            "897 3.7822988169366227\n",
            "898 3.7790937245500036\n",
            "899 3.775912810770635\n",
            "900 3.7727558930089566\n",
            "901 3.769622790054267\n",
            "902 3.7665133220643168\n",
            "903 3.763427310554978\n",
            "904 3.7603645783899755\n",
            "905 3.7573249497707217\n",
            "906 3.7543082502262077\n",
            "907 3.751314306602977\n",
            "908 3.74834294705518\n",
            "909 3.7453940010346964\n",
            "910 3.7424672992813344\n",
            "911 3.739562673813108\n",
            "912 3.73667995791658\n",
            "913 3.7338189861372864\n",
            "914 3.7309795942702273\n",
            "915 3.72816161935043\n",
            "916 3.7253648996435857\n",
            "917 3.7225892746367566\n",
            "918 3.7198345850291514\n",
            "919 3.7171006727229736\n",
            "920 3.714387380814332\n",
            "921 3.7116945535842274\n",
            "922 3.709022036489612\n",
            "923 3.706369676154492\n",
            "924 3.70373732036113\n",
            "925 3.701124818041293\n",
            "926 3.698532019267568\n",
            "927 3.6959587752447534\n",
            "928 3.693404938301301\n",
            "929 3.69087036188084\n",
            "930 3.6883549005337444\n",
            "931 3.685858409908785\n",
            "932 3.6833807467448345\n",
            "933 3.6809217688626212\n",
            "934 3.67848133515658\n",
            "935 3.6760593055867274\n",
            "936 3.673655541170624\n",
            "937 3.6712699039753818\n",
            "938 3.668902257109743\n",
            "939 3.666552464716214\n",
            "940 3.6642203919632563\n",
            "941 3.661905905037537\n",
            "942 3.659608871136246\n",
            "943 3.657329158459456\n",
            "944 3.6550666362025606\n",
            "945 3.6528211745487456\n",
            "946 3.6505926446615375\n",
            "947 3.6483809186773986\n",
            "948 3.6461858696983755\n",
            "949 3.644007371784818\n",
            "950 3.641845299948126\n",
            "951 3.639699530143584\n",
            "952 3.63756993926322\n",
            "953 3.6354564051287435\n",
            "954 3.6333588064845115\n",
            "955 3.631277022990572\n",
            "956 3.6292109352157427\n",
            "957 3.6271604246307536\n",
            "958 3.6251253736014304\n",
            "959 3.623105665381936\n",
            "960 3.621101184108068\n",
            "961 3.619111814790591\n",
            "962 3.6171374433086383\n",
            "963 3.615177956403148\n",
            "964 3.6132332416703576\n",
            "965 3.6113031875553463\n",
            "966 3.6093876833456204\n",
            "967 3.6074866191647583\n",
            "968 3.6055998859660874\n",
            "969 3.603727375526428\n",
            "970 3.6018689804398667\n",
            "971 3.60002459411159\n",
            "972 3.598194110751756\n",
            "973 3.596377425369417\n",
            "974 3.594574433766484\n",
            "975 3.5927850325317423\n",
            "976 3.59100911903491\n",
            "977 3.589246591420738\n",
            "978 3.5874973486031547\n",
            "979 3.585761290259463\n",
            "980 3.5840383168245764\n",
            "981 3.5823283294852866\n",
            "982 3.5806312301746015\n",
            "983 3.5789469215660983\n",
            "984 3.5772753070683323\n",
            "985 3.575616290819295\n",
            "986 3.573969777680893\n",
            "987 3.5723356732334905\n",
            "988 3.5707138837704817\n",
            "989 3.5691043162929033\n",
            "990 3.5675068785040946\n",
            "991 3.56592147880439\n",
            "992 3.5643480262858604\n",
            "993 3.5627864307270833\n",
            "994 3.5612366025879627\n",
            "995 3.5596984530045845\n",
            "996 3.5581718937841065\n",
            "997 3.5566568373996925\n",
            "998 3.5551531969854864\n",
            "999 3.553660886331612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae = abs(y - yh).mean()\n",
        "print(mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffGUNFKp8R6K",
        "outputId": "5c86748d-0895-41aa-8c24-4ad7e0a72e91"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3739188313235315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perceptron Model using Keras**"
      ],
      "metadata": {
        "id": "GeQVtTAL810p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1** - Define or collect data"
      ],
      "metadata": {
        "id": "wDB5IgCe89V2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns = 'sales')\n",
        "y = df['sales']"
      ],
      "metadata": {
        "id": "xaCIlOrH9C1Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Xw_xaCyG-XkE",
        "outputId": "8bb6dfb5-2e9e-400a-f1ec-e1e1867fecfa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      TV  radio  newspaper\n",
              "1  230.1   37.8       69.2\n",
              "2   44.5   39.3       45.1\n",
              "3   17.2   45.9       69.3\n",
              "4  151.5   41.3       58.5\n",
              "5  180.8   10.8       58.4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c25c10d-c9ab-4c3a-9014-d00df3dbc5cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TV</th>\n",
              "      <th>radio</th>\n",
              "      <th>newspaper</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230.1</td>\n",
              "      <td>37.8</td>\n",
              "      <td>69.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44.5</td>\n",
              "      <td>39.3</td>\n",
              "      <td>45.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17.2</td>\n",
              "      <td>45.9</td>\n",
              "      <td>69.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>151.5</td>\n",
              "      <td>41.3</td>\n",
              "      <td>58.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>180.8</td>\n",
              "      <td>10.8</td>\n",
              "      <td>58.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c25c10d-c9ab-4c3a-9014-d00df3dbc5cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c25c10d-c9ab-4c3a-9014-d00df3dbc5cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c25c10d-c9ab-4c3a-9014-d00df3dbc5cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b0fa2cae-2766-4e17-8f05-e7c4cc99051d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0fa2cae-2766-4e17-8f05-e7c4cc99051d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b0fa2cae-2766-4e17-8f05-e7c4cc99051d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 200,\n  \"fields\": [\n    {\n      \"column\": \"TV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85.8542363149081,\n        \"min\": 0.7,\n        \"max\": 296.4,\n        \"num_unique_values\": 190,\n        \"samples\": [\n          287.6,\n          286.0,\n          78.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"radio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.846809176168723,\n        \"min\": 0.0,\n        \"max\": 49.6,\n        \"num_unique_values\": 167,\n        \"samples\": [\n          8.2,\n          36.9,\n          44.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"newspaper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.778620838522833,\n        \"min\": 0.3,\n        \"max\": 114.0,\n        \"num_unique_values\": 172,\n        \"samples\": [\n          22.3,\n          5.7,\n          17.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "Xs = scaler.transform(X)"
      ],
      "metadata": {
        "id": "OIU9L-lCA1W2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2** - Create neural network"
      ],
      "metadata": {
        "id": "kfCRN4IJ9DNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models,layers\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(1 , activation='relu' , input_shape = (3,)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCdMf44e8kS9",
        "outputId": "5544b612-3e4f-485c-9431-5e9fcf1fe8e4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "ehRPTaN79SKk",
        "outputId": "d9911b9d-e0e8-4878-f045-54527a04dc9b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense_5 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                           \u001b[38;5;34m4\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4\u001b[0m (16.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> (16.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4\u001b[0m (16.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> (16.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3** - Compile the neural network"
      ],
      "metadata": {
        "id": "GRJ0UE8A97kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "sgd = optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "model.compile(optimizer = sgd, loss = 'mse', metrics = ['mae'])"
      ],
      "metadata": {
        "id": "GB2Z0eSc9suI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4** - Train the model"
      ],
      "metadata": {
        "id": "obW7TaBi-Nco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Xs,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGVHytQv-M1x",
        "outputId": "51a0d0e9-e11c-4ace-fe8d-12e37944bb7f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 208.4148 - mae: 13.4616  \n",
            "Epoch 2/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 138.8526 - mae: 10.7294 \n",
            "Epoch 3/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 94.4871 - mae: 8.7097   \n",
            "Epoch 4/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 61.3059 - mae: 6.7103 \n",
            "Epoch 5/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 42.1652 - mae: 5.4008 \n",
            "Epoch 6/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 29.5842 - mae: 4.4735 \n",
            "Epoch 7/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.6034 - mae: 3.6501 \n",
            "Epoch 8/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.7549 - mae: 3.2228 \n",
            "Epoch 9/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.5718 - mae: 3.0936  \n",
            "Epoch 10/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.0157 - mae: 2.9204 \n",
            "Epoch 11/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.5509 - mae: 2.5152\n",
            "Epoch 12/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.9102 - mae: 2.4757 \n",
            "Epoch 13/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3722 - mae: 2.2769  \n",
            "Epoch 14/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.4368 - mae: 2.4829 \n",
            "Epoch 15/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4327 - mae: 2.3195 \n",
            "Epoch 16/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0930 - mae: 2.3895 \n",
            "Epoch 17/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.4860 - mae: 2.4848 \n",
            "Epoch 18/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8778 - mae: 2.2273 \n",
            "Epoch 19/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1745 - mae: 2.2973 \n",
            "Epoch 20/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4104 - mae: 2.3508 \n",
            "Epoch 21/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.6467 - mae: 2.2618 \n",
            "Epoch 22/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.6060 - mae: 2.2367 \n",
            "Epoch 23/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.5099 - mae: 2.2535 \n",
            "Epoch 24/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1348 - mae: 2.1987 \n",
            "Epoch 25/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2809 - mae: 2.2550 \n",
            "Epoch 26/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9798 - mae: 2.1689 \n",
            "Epoch 27/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0627 - mae: 2.1702 \n",
            "Epoch 28/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7961 - mae: 2.1972 \n",
            "Epoch 29/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.7285 - mae: 2.3079   \n",
            "Epoch 30/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8504 - mae: 2.1741 \n",
            "Epoch 31/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9821 - mae: 2.3157  \n",
            "Epoch 32/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4806 - mae: 2.0271 \n",
            "Epoch 33/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5736 - mae: 1.9467 \n",
            "Epoch 34/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9687 - mae: 2.1199 \n",
            "Epoch 35/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9833 - mae: 2.0269 \n",
            "Epoch 36/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6295 - mae: 2.1904 \n",
            "Epoch 37/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9664 - mae: 2.0933  \n",
            "Epoch 38/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1071 - mae: 2.2057 \n",
            "Epoch 39/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3528 - mae: 1.9995 \n",
            "Epoch 40/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3204 - mae: 2.0646 \n",
            "Epoch 41/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0676 - mae: 1.9901 \n",
            "Epoch 42/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2464 - mae: 1.8996 \n",
            "Epoch 43/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8593 - mae: 1.9912 \n",
            "Epoch 44/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2722 - mae: 2.0492  \n",
            "Epoch 45/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2007 - mae: 2.0451 \n",
            "Epoch 46/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2084 - mae: 1.8970 \n",
            "Epoch 47/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5423 - mae: 1.8944 \n",
            "Epoch 48/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2145 - mae: 1.8838 \n",
            "Epoch 49/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4106 - mae: 1.8823 \n",
            "Epoch 50/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6079 - mae: 1.9281 \n",
            "Epoch 51/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0255 - mae: 2.0109  \n",
            "Epoch 52/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8424 - mae: 1.8046 \n",
            "Epoch 53/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2878 - mae: 1.8478 \n",
            "Epoch 54/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0560 - mae: 1.8315  \n",
            "Epoch 55/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6930 - mae: 1.9314  \n",
            "Epoch 56/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2422 - mae: 1.8555 \n",
            "Epoch 57/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0035 - mae: 1.8334  \n",
            "Epoch 58/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7892 - mae: 1.7843 \n",
            "Epoch 59/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7208 - mae: 1.8073 \n",
            "Epoch 60/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3681 - mae: 1.7168 \n",
            "Epoch 61/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6598 - mae: 1.8321 \n",
            "Epoch 62/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.8901 - mae: 1.7911 \n",
            "Epoch 63/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5154 - mae: 1.8863 \n",
            "Epoch 64/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.8218 - mae: 1.6068 \n",
            "Epoch 65/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.7863 - mae: 1.8057 \n",
            "Epoch 66/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2977 - mae: 1.8430  \n",
            "Epoch 67/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0680 - mae: 1.6386 \n",
            "Epoch 68/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1458 - mae: 1.6707 \n",
            "Epoch 69/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6163 - mae: 1.7499 \n",
            "Epoch 70/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.9579 - mae: 1.7301 \n",
            "Epoch 71/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6676 - mae: 1.7152 \n",
            "Epoch 72/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.1852 - mae: 1.6807 \n",
            "Epoch 73/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.7042 - mae: 1.7046 \n",
            "Epoch 74/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.7031 - mae: 1.7219 \n",
            "Epoch 75/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7662 - mae: 1.5735 \n",
            "Epoch 76/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4710 - mae: 1.6889 \n",
            "Epoch 77/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5116 - mae: 1.7269 \n",
            "Epoch 78/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5349 - mae: 1.5700 \n",
            "Epoch 79/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6098 - mae: 1.5584 \n",
            "Epoch 80/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0198 - mae: 1.6709 \n",
            "Epoch 81/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6783 - mae: 1.5975 \n",
            "Epoch 82/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4955 - mae: 1.6565 \n",
            "Epoch 83/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5435 - mae: 1.5700 \n",
            "Epoch 84/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9939 - mae: 1.6001 \n",
            "Epoch 85/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7555 - mae: 1.6163 \n",
            "Epoch 86/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.5423 - mae: 1.6875 \n",
            "Epoch 87/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0904 - mae: 1.6051 \n",
            "Epoch 88/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7382 - mae: 1.5636 \n",
            "Epoch 89/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7083 - mae: 1.5559 \n",
            "Epoch 90/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0043 - mae: 1.4546 \n",
            "Epoch 91/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9262 - mae: 1.6054 \n",
            "Epoch 92/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5086 - mae: 1.5416 \n",
            "Epoch 93/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1411 - mae: 1.4384 \n",
            "Epoch 94/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2326 - mae: 1.6242 \n",
            "Epoch 95/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4410 - mae: 1.5087  \n",
            "Epoch 96/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4661 - mae: 1.5272 \n",
            "Epoch 97/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.0458 - mae: 1.4447 \n",
            "Epoch 98/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7732 - mae: 1.4055 \n",
            "Epoch 99/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3848 - mae: 1.4943 \n",
            "Epoch 100/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.3152 - mae: 1.4723 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x781abe7798d0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(Xs,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FrlsWX9-ZX6",
        "outputId": "1b8af5b6-f17b-459b-a494-86eede96e38a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.3628 - mae: 1.5118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.373175621032715, 1.5000039339065552]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deep Neural Network**"
      ],
      "metadata": {
        "id": "yEPAdyOfBgTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain,xtest,ytrain,ytest = train_test_split(Xs,y)"
      ],
      "metadata": {
        "id": "NRdz3N4uCOeC"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models,layers\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(2 , activation='relu' , input_shape = (3,)))\n",
        "\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9qyDre6_H6z",
        "outputId": "b092d616-bf43-472d-8abd-d8a6f1287fdf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "aqwMLDK3BpRt",
        "outputId": "3c264cac-6ca3-49dd-b49e-9ffac3699adc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " dense_8 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                           \u001b[38;5;34m8\u001b[0m \n",
              "\n",
              " dense_9 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                           \u001b[38;5;34m3\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> \n",
              "\n",
              " dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11\u001b[0m (44.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> (44.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11\u001b[0m (44.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> (44.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "sgd = optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "model.compile(optimizer = sgd, loss = 'mse', metrics = ['mae'])"
      ],
      "metadata": {
        "id": "se-pBXlqB0mf"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xtrain,ytrain,epochs=500,\n",
        "          validation_data = (xtest,ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BEJR6RXB7Pl",
        "outputId": "3e83f9e7-c225-4ed5-8062-c63b19ad415a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - loss: 5.3954 - mae: 1.7315 - val_loss: 3.0834 - val_mae: 1.4424\n",
            "Epoch 2/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.1090 - mae: 1.7329 - val_loss: 3.3328 - val_mae: 1.3146\n",
            "Epoch 3/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.5658 - mae: 1.5143 - val_loss: 3.0736 - val_mae: 1.4080\n",
            "Epoch 4/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.2771 - mae: 1.5122 - val_loss: 3.0568 - val_mae: 1.4139\n",
            "Epoch 5/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.6745 - mae: 1.6194 - val_loss: 3.2624 - val_mae: 1.3179\n",
            "Epoch 6/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.3952 - mae: 1.4904 - val_loss: 3.0668 - val_mae: 1.4462\n",
            "Epoch 7/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.4650 - mae: 1.5988 - val_loss: 3.1046 - val_mae: 1.4858\n",
            "Epoch 8/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.3359 - mae: 1.7120 - val_loss: 3.2980 - val_mae: 1.3095\n",
            "Epoch 9/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.6251 - mae: 1.4934 - val_loss: 3.1036 - val_mae: 1.3366\n",
            "Epoch 10/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.0122 - mae: 1.4663 - val_loss: 3.1290 - val_mae: 1.5059\n",
            "Epoch 11/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.7686 - mae: 1.6205 - val_loss: 3.1091 - val_mae: 1.3586\n",
            "Epoch 12/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 4.0184 - mae: 1.5000 - val_loss: 3.0731 - val_mae: 1.3622\n",
            "Epoch 13/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 4.5367 - mae: 1.5282 - val_loss: 3.0595 - val_mae: 1.3549\n",
            "Epoch 14/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.6133 - mae: 1.5964 - val_loss: 3.2929 - val_mae: 1.3053\n",
            "Epoch 15/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.6700 - mae: 1.5345 - val_loss: 3.1117 - val_mae: 1.3267\n",
            "Epoch 16/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.3552 - mae: 1.5339 - val_loss: 3.0447 - val_mae: 1.4333\n",
            "Epoch 17/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.7328 - mae: 1.4408 - val_loss: 3.0290 - val_mae: 1.3816\n",
            "Epoch 18/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.5626 - mae: 1.5500 - val_loss: 3.1200 - val_mae: 1.3446\n",
            "Epoch 19/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.2248 - mae: 1.4964 - val_loss: 3.0762 - val_mae: 1.3749\n",
            "Epoch 20/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.9518 - mae: 1.4875 - val_loss: 3.1924 - val_mae: 1.3179\n",
            "Epoch 21/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.2249 - mae: 1.6284 - val_loss: 3.0402 - val_mae: 1.3881\n",
            "Epoch 22/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.1157 - mae: 1.4850 - val_loss: 3.0759 - val_mae: 1.4509\n",
            "Epoch 23/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.3555 - mae: 1.5918 - val_loss: 3.0262 - val_mae: 1.4021\n",
            "Epoch 24/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.9231 - mae: 1.4872 - val_loss: 3.1739 - val_mae: 1.3119\n",
            "Epoch 25/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.0600 - mae: 1.5507 - val_loss: 3.0199 - val_mae: 1.4056\n",
            "Epoch 26/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.5659 - mae: 1.5896 - val_loss: 3.2180 - val_mae: 1.3083\n",
            "Epoch 27/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.7098 - mae: 1.4288 - val_loss: 3.1063 - val_mae: 1.3312\n",
            "Epoch 28/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.4647 - mae: 1.5459 - val_loss: 3.5324 - val_mae: 1.3275\n",
            "Epoch 29/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.5988 - mae: 1.5948 - val_loss: 3.0751 - val_mae: 1.3638\n",
            "Epoch 30/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.8154 - mae: 1.4409 - val_loss: 3.1234 - val_mae: 1.4763\n",
            "Epoch 31/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.2723 - mae: 1.6095 - val_loss: 3.1541 - val_mae: 1.3324\n",
            "Epoch 32/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.1000 - mae: 1.4863 - val_loss: 3.0887 - val_mae: 1.4706\n",
            "Epoch 33/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.7956 - mae: 1.4858 - val_loss: 3.1723 - val_mae: 1.3123\n",
            "Epoch 34/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6959 - mae: 1.4493 - val_loss: 3.0856 - val_mae: 1.4533\n",
            "Epoch 35/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.9823 - mae: 1.5422 - val_loss: 3.2948 - val_mae: 1.3149\n",
            "Epoch 36/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.5142 - mae: 1.4128 - val_loss: 3.0747 - val_mae: 1.3519\n",
            "Epoch 37/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.9757 - mae: 1.4716 - val_loss: 3.2715 - val_mae: 1.3126\n",
            "Epoch 38/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.2567 - mae: 1.2994 - val_loss: 3.0881 - val_mae: 1.3345\n",
            "Epoch 39/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6364 - mae: 1.4579 - val_loss: 3.2838 - val_mae: 1.3045\n",
            "Epoch 40/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.5441 - mae: 1.5143 - val_loss: 3.1587 - val_mae: 1.3030\n",
            "Epoch 41/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.1379 - mae: 1.5020 - val_loss: 3.0249 - val_mae: 1.4151\n",
            "Epoch 42/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.3277 - mae: 1.5558 - val_loss: 3.3317 - val_mae: 1.3066\n",
            "Epoch 43/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.5457 - mae: 1.5898 - val_loss: 3.0538 - val_mae: 1.3169\n",
            "Epoch 44/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.4292 - mae: 1.3780 - val_loss: 3.0198 - val_mae: 1.4268\n",
            "Epoch 45/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.0293 - mae: 1.4994 - val_loss: 3.0319 - val_mae: 1.3520\n",
            "Epoch 46/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.0945 - mae: 1.5032 - val_loss: 3.2498 - val_mae: 1.2976\n",
            "Epoch 47/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6785 - mae: 1.4186 - val_loss: 3.2242 - val_mae: 1.3028\n",
            "Epoch 48/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.7387 - mae: 1.4550 - val_loss: 3.5449 - val_mae: 1.3301\n",
            "Epoch 49/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6973 - mae: 1.4146 - val_loss: 3.1550 - val_mae: 1.3183\n",
            "Epoch 50/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.3968 - mae: 1.3719 - val_loss: 3.0866 - val_mae: 1.3661\n",
            "Epoch 51/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.3286 - mae: 1.3761 - val_loss: 3.0864 - val_mae: 1.4043\n",
            "Epoch 52/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6227 - mae: 1.4623 - val_loss: 3.1968 - val_mae: 1.3186\n",
            "Epoch 53/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.8853 - mae: 1.4605 - val_loss: 3.2394 - val_mae: 1.3126\n",
            "Epoch 54/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.1544 - mae: 1.2850 - val_loss: 3.2021 - val_mae: 1.3058\n",
            "Epoch 55/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.1567 - mae: 1.2613 - val_loss: 3.2070 - val_mae: 1.3032\n",
            "Epoch 56/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.8561 - mae: 1.4422 - val_loss: 3.1369 - val_mae: 1.3034\n",
            "Epoch 57/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.0033 - mae: 1.5307 - val_loss: 3.0597 - val_mae: 1.3294\n",
            "Epoch 58/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.2068 - mae: 1.3209 - val_loss: 3.0241 - val_mae: 1.4198\n",
            "Epoch 59/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.8917 - mae: 1.5301 - val_loss: 3.0206 - val_mae: 1.4153\n",
            "Epoch 60/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.4980 - mae: 1.4521 - val_loss: 3.1516 - val_mae: 1.5104\n",
            "Epoch 61/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.7317 - mae: 1.5301 - val_loss: 3.0426 - val_mae: 1.3601\n",
            "Epoch 62/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.1334 - mae: 1.3837 - val_loss: 3.0560 - val_mae: 1.4362\n",
            "Epoch 63/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.4917 - mae: 1.4798 - val_loss: 3.2197 - val_mae: 1.3037\n",
            "Epoch 64/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.5313 - mae: 1.3376 - val_loss: 3.0606 - val_mae: 1.3555\n",
            "Epoch 65/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6484 - mae: 1.4229 - val_loss: 3.1554 - val_mae: 1.4963\n",
            "Epoch 66/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.8067 - mae: 1.5427 - val_loss: 3.1371 - val_mae: 1.3168\n",
            "Epoch 67/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.2418 - mae: 1.3539 - val_loss: 3.3824 - val_mae: 1.3153\n",
            "Epoch 68/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6392 - mae: 1.5130 - val_loss: 3.5185 - val_mae: 1.3251\n",
            "Epoch 69/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.4165 - mae: 1.3991 - val_loss: 3.1061 - val_mae: 1.3067\n",
            "Epoch 70/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.1195 - mae: 1.3000 - val_loss: 3.0331 - val_mae: 1.3425\n",
            "Epoch 71/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6377 - mae: 1.4238 - val_loss: 3.4816 - val_mae: 1.3191\n",
            "Epoch 72/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.5572 - mae: 1.4159 - val_loss: 3.0105 - val_mae: 1.3377\n",
            "Epoch 73/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.4232 - mae: 1.4154 - val_loss: 3.2671 - val_mae: 1.2975\n",
            "Epoch 74/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.9571 - mae: 1.2806 - val_loss: 3.3530 - val_mae: 1.3048\n",
            "Epoch 75/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.8559 - mae: 1.4708 - val_loss: 3.0622 - val_mae: 1.3029\n",
            "Epoch 76/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9205 - mae: 1.2930 - val_loss: 2.9977 - val_mae: 1.3740\n",
            "Epoch 77/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.3044 - mae: 1.4164 - val_loss: 3.1691 - val_mae: 1.2983\n",
            "Epoch 78/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.4362 - mae: 1.3487 - val_loss: 3.0375 - val_mae: 1.3317\n",
            "Epoch 79/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0565 - mae: 1.3690 - val_loss: 3.0358 - val_mae: 1.3985\n",
            "Epoch 80/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.3330 - mae: 1.4410 - val_loss: 3.3004 - val_mae: 1.3098\n",
            "Epoch 81/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.5049 - mae: 1.2266 - val_loss: 3.0437 - val_mae: 1.3868\n",
            "Epoch 82/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6079 - mae: 1.4813 - val_loss: 3.0322 - val_mae: 1.4011\n",
            "Epoch 83/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.2129 - mae: 1.3584 - val_loss: 3.1098 - val_mae: 1.3186\n",
            "Epoch 84/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9189 - mae: 1.2810 - val_loss: 3.0451 - val_mae: 1.3647\n",
            "Epoch 85/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.8113 - mae: 1.5399 - val_loss: 3.2459 - val_mae: 1.3083\n",
            "Epoch 86/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.3921 - mae: 1.4066 - val_loss: 3.1314 - val_mae: 1.3137\n",
            "Epoch 87/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.9186 - mae: 1.4631 - val_loss: 3.2893 - val_mae: 1.3102\n",
            "Epoch 88/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.5583 - mae: 1.3562 - val_loss: 3.1496 - val_mae: 1.3001\n",
            "Epoch 89/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.9349 - mae: 1.2917 - val_loss: 3.2028 - val_mae: 1.2949\n",
            "Epoch 90/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.1000 - mae: 1.3512 - val_loss: 3.0237 - val_mae: 1.3552\n",
            "Epoch 91/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.1562 - mae: 1.3770 - val_loss: 3.2876 - val_mae: 1.3037\n",
            "Epoch 92/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.9047 - mae: 1.3070 - val_loss: 3.0143 - val_mae: 1.3720\n",
            "Epoch 93/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.0668 - mae: 1.3886 - val_loss: 3.1507 - val_mae: 1.3084\n",
            "Epoch 94/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.1153 - mae: 1.3047 - val_loss: 3.1824 - val_mae: 1.3049\n",
            "Epoch 95/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1316 - mae: 1.3566 - val_loss: 3.0993 - val_mae: 1.3154\n",
            "Epoch 96/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7948 - mae: 1.2785 - val_loss: 3.0129 - val_mae: 1.4218\n",
            "Epoch 97/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7336 - mae: 1.2693 - val_loss: 3.1632 - val_mae: 1.2949\n",
            "Epoch 98/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0485 - mae: 1.3336 - val_loss: 3.0076 - val_mae: 1.3239\n",
            "Epoch 99/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6730 - mae: 1.2811 - val_loss: 3.0911 - val_mae: 1.4810\n",
            "Epoch 100/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.1374 - mae: 1.4197 - val_loss: 3.3168 - val_mae: 1.3036\n",
            "Epoch 101/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.0863 - mae: 1.2838 - val_loss: 3.2723 - val_mae: 1.3045\n",
            "Epoch 102/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.6624 - mae: 1.3841 - val_loss: 3.1062 - val_mae: 1.3064\n",
            "Epoch 103/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.4308 - mae: 1.3695 - val_loss: 3.1449 - val_mae: 1.3047\n",
            "Epoch 104/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9227 - mae: 1.3068 - val_loss: 3.3102 - val_mae: 1.3093\n",
            "Epoch 105/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1956 - mae: 1.3641 - val_loss: 3.2659 - val_mae: 1.3031\n",
            "Epoch 106/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.9140 - mae: 1.4175 - val_loss: 3.1392 - val_mae: 1.3052\n",
            "Epoch 107/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0126 - mae: 1.3446 - val_loss: 3.1058 - val_mae: 1.3019\n",
            "Epoch 108/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.2967 - mae: 1.2970 - val_loss: 3.0587 - val_mae: 1.3133\n",
            "Epoch 109/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9896 - mae: 1.3460 - val_loss: 2.9832 - val_mae: 1.3683\n",
            "Epoch 110/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.9067 - mae: 1.3431 - val_loss: 3.0478 - val_mae: 1.3022\n",
            "Epoch 111/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9607 - mae: 1.3610 - val_loss: 3.3950 - val_mae: 1.3087\n",
            "Epoch 112/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8020 - mae: 1.2806 - val_loss: 3.0116 - val_mae: 1.3504\n",
            "Epoch 113/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.8263 - mae: 1.3337 - val_loss: 3.1499 - val_mae: 1.2950\n",
            "Epoch 114/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8840 - mae: 1.2984 - val_loss: 3.1700 - val_mae: 1.5233\n",
            "Epoch 115/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0840 - mae: 1.4147 - val_loss: 3.1137 - val_mae: 1.3056\n",
            "Epoch 116/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9958 - mae: 1.3622 - val_loss: 3.1565 - val_mae: 1.2982\n",
            "Epoch 117/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6123 - mae: 1.4199 - val_loss: 3.7585 - val_mae: 1.3658\n",
            "Epoch 118/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.4393 - mae: 1.4386 - val_loss: 3.2516 - val_mae: 1.2983\n",
            "Epoch 119/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.9805 - mae: 1.2665 - val_loss: 3.1073 - val_mae: 1.3032\n",
            "Epoch 120/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5796 - mae: 1.2581 - val_loss: 3.0744 - val_mae: 1.3398\n",
            "Epoch 121/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.8735 - mae: 1.3263 - val_loss: 3.2691 - val_mae: 1.3068\n",
            "Epoch 122/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1171 - mae: 1.3153 - val_loss: 3.2717 - val_mae: 1.3067\n",
            "Epoch 123/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8478 - mae: 1.2924 - val_loss: 3.4244 - val_mae: 1.3162\n",
            "Epoch 124/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.3328 - mae: 1.3711 - val_loss: 3.0223 - val_mae: 1.3428\n",
            "Epoch 125/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7220 - mae: 1.2523 - val_loss: 3.0886 - val_mae: 1.3179\n",
            "Epoch 126/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.8721 - mae: 1.2964 - val_loss: 3.0897 - val_mae: 1.3090\n",
            "Epoch 127/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3322 - mae: 1.3655 - val_loss: 3.1843 - val_mae: 1.3063\n",
            "Epoch 128/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1880 - mae: 1.4000 - val_loss: 3.0852 - val_mae: 1.3214\n",
            "Epoch 129/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9302 - mae: 1.2826 - val_loss: 3.3993 - val_mae: 1.3183\n",
            "Epoch 130/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1111 - mae: 1.3642 - val_loss: 3.2250 - val_mae: 1.3042\n",
            "Epoch 131/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4955 - mae: 1.2162 - val_loss: 3.1583 - val_mae: 1.3001\n",
            "Epoch 132/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7066 - mae: 1.2798 - val_loss: 3.0220 - val_mae: 1.3703\n",
            "Epoch 133/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8103 - mae: 1.3423 - val_loss: 3.0944 - val_mae: 1.3469\n",
            "Epoch 134/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7560 - mae: 1.3044 - val_loss: 3.2800 - val_mae: 1.3135\n",
            "Epoch 135/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.5312 - mae: 1.3600 - val_loss: 3.2490 - val_mae: 1.3084\n",
            "Epoch 136/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9279 - mae: 1.3132 - val_loss: 3.1334 - val_mae: 1.3175\n",
            "Epoch 137/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.1904 - mae: 1.3506 - val_loss: 3.3501 - val_mae: 1.3192\n",
            "Epoch 138/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7900 - mae: 1.2571 - val_loss: 3.3866 - val_mae: 1.3231\n",
            "Epoch 139/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8575 - mae: 1.3238 - val_loss: 3.3660 - val_mae: 1.3202\n",
            "Epoch 140/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6637 - mae: 1.2784 - val_loss: 3.0974 - val_mae: 1.3791\n",
            "Epoch 141/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8351 - mae: 1.2880 - val_loss: 3.1458 - val_mae: 1.3459\n",
            "Epoch 142/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2174 - mae: 1.4020 - val_loss: 3.2203 - val_mae: 1.3200\n",
            "Epoch 143/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.5156 - mae: 1.4007 - val_loss: 3.2488 - val_mae: 1.3149\n",
            "Epoch 144/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9062 - mae: 1.2967 - val_loss: 3.0496 - val_mae: 1.3651\n",
            "Epoch 145/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6205 - mae: 1.2373 - val_loss: 3.5579 - val_mae: 1.3414\n",
            "Epoch 146/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.3541 - mae: 1.3523 - val_loss: 3.0206 - val_mae: 1.3998\n",
            "Epoch 147/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7634 - mae: 1.3164 - val_loss: 3.1344 - val_mae: 1.3084\n",
            "Epoch 148/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6794 - mae: 1.4228 - val_loss: 3.2632 - val_mae: 1.3048\n",
            "Epoch 149/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9422 - mae: 1.2727 - val_loss: 3.0540 - val_mae: 1.3694\n",
            "Epoch 150/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.4585 - mae: 1.4370 - val_loss: 3.1006 - val_mae: 1.3396\n",
            "Epoch 151/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0519 - mae: 1.3189 - val_loss: 3.3685 - val_mae: 1.3194\n",
            "Epoch 152/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8909 - mae: 1.3093 - val_loss: 3.0498 - val_mae: 1.3793\n",
            "Epoch 153/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2811 - mae: 1.3840 - val_loss: 3.2757 - val_mae: 1.3145\n",
            "Epoch 154/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2247 - mae: 1.3136 - val_loss: 3.3125 - val_mae: 1.3189\n",
            "Epoch 155/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8665 - mae: 1.3198 - val_loss: 3.2211 - val_mae: 1.3087\n",
            "Epoch 156/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1920 - mae: 1.4176 - val_loss: 3.2150 - val_mae: 1.3047\n",
            "Epoch 157/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7034 - mae: 1.3043 - val_loss: 3.0650 - val_mae: 1.4523\n",
            "Epoch 158/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1230 - mae: 1.4183 - val_loss: 3.2063 - val_mae: 1.3072\n",
            "Epoch 159/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9439 - mae: 1.3130 - val_loss: 3.1857 - val_mae: 1.3110\n",
            "Epoch 160/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6682 - mae: 1.2981 - val_loss: 3.2750 - val_mae: 1.3161\n",
            "Epoch 161/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.1277 - mae: 1.2832 - val_loss: 3.2095 - val_mae: 1.3081\n",
            "Epoch 162/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.5136 - mae: 1.4003 - val_loss: 3.3753 - val_mae: 1.3204\n",
            "Epoch 163/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.4658 - mae: 1.1865 - val_loss: 3.2115 - val_mae: 1.3102\n",
            "Epoch 164/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1479 - mae: 1.2592 - val_loss: 3.1799 - val_mae: 1.3110\n",
            "Epoch 165/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.1917 - mae: 1.3440 - val_loss: 3.3753 - val_mae: 1.3253\n",
            "Epoch 166/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5834 - mae: 1.2514 - val_loss: 3.0931 - val_mae: 1.3484\n",
            "Epoch 167/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9185 - mae: 1.3416 - val_loss: 3.4308 - val_mae: 1.3325\n",
            "Epoch 168/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7944 - mae: 1.3357 - val_loss: 3.0698 - val_mae: 1.3879\n",
            "Epoch 169/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.4175 - mae: 1.3891 - val_loss: 3.0417 - val_mae: 1.3854\n",
            "Epoch 170/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6305 - mae: 1.4481 - val_loss: 3.2828 - val_mae: 1.3152\n",
            "Epoch 171/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9978 - mae: 1.2976 - val_loss: 3.0345 - val_mae: 1.3647\n",
            "Epoch 172/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8767 - mae: 1.3423 - val_loss: 3.0512 - val_mae: 1.3400\n",
            "Epoch 173/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7380 - mae: 1.2370 - val_loss: 3.4850 - val_mae: 1.3323\n",
            "Epoch 174/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8520 - mae: 1.3019 - val_loss: 3.0334 - val_mae: 1.3679\n",
            "Epoch 175/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8274 - mae: 1.3022 - val_loss: 3.2878 - val_mae: 1.3128\n",
            "Epoch 176/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3365 - mae: 1.3148 - val_loss: 3.6816 - val_mae: 1.3613\n",
            "Epoch 177/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6708 - mae: 1.3631 - val_loss: 3.3105 - val_mae: 1.3127\n",
            "Epoch 178/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6662 - mae: 1.2878 - val_loss: 3.0717 - val_mae: 1.3911\n",
            "Epoch 179/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7997 - mae: 1.2666 - val_loss: 3.2120 - val_mae: 1.3168\n",
            "Epoch 180/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.6136 - mae: 1.2459 - val_loss: 3.2392 - val_mae: 1.3196\n",
            "Epoch 181/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.7594 - mae: 1.2313 - val_loss: 3.0870 - val_mae: 1.3730\n",
            "Epoch 182/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.1135 - mae: 1.3600 - val_loss: 3.6014 - val_mae: 1.3532\n",
            "Epoch 183/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.7629 - mae: 1.2473 - val_loss: 3.1829 - val_mae: 1.3120\n",
            "Epoch 184/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.3171 - mae: 1.3346 - val_loss: 3.0977 - val_mae: 1.3325\n",
            "Epoch 185/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.7841 - mae: 1.2938 - val_loss: 3.1126 - val_mae: 1.3262\n",
            "Epoch 186/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.9081 - mae: 1.2828 - val_loss: 3.2449 - val_mae: 1.3159\n",
            "Epoch 187/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.1224 - mae: 1.2675 - val_loss: 3.1718 - val_mae: 1.3136\n",
            "Epoch 188/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.4333 - mae: 1.2169 - val_loss: 3.0824 - val_mae: 1.4212\n",
            "Epoch 189/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7420 - mae: 1.3479 - val_loss: 3.1571 - val_mae: 1.4512\n",
            "Epoch 190/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.8528 - mae: 1.3940 - val_loss: 3.1423 - val_mae: 1.3737\n",
            "Epoch 191/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2573 - mae: 1.3563 - val_loss: 3.1817 - val_mae: 1.3790\n",
            "Epoch 192/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7631 - mae: 1.3180 - val_loss: 3.2070 - val_mae: 1.3824\n",
            "Epoch 193/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1135 - mae: 1.3865 - val_loss: 3.3507 - val_mae: 1.3399\n",
            "Epoch 194/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8280 - mae: 1.3067 - val_loss: 3.2501 - val_mae: 1.3490\n",
            "Epoch 195/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7197 - mae: 1.3014 - val_loss: 3.1838 - val_mae: 1.3846\n",
            "Epoch 196/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2600 - mae: 1.3515 - val_loss: 3.3265 - val_mae: 1.3459\n",
            "Epoch 197/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4480 - mae: 1.2188 - val_loss: 3.2442 - val_mae: 1.3532\n",
            "Epoch 198/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.5979 - mae: 1.2564 - val_loss: 3.4498 - val_mae: 1.3526\n",
            "Epoch 199/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0186 - mae: 1.3710 - val_loss: 3.7007 - val_mae: 1.3776\n",
            "Epoch 200/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5724 - mae: 1.1753 - val_loss: 3.2025 - val_mae: 1.4842\n",
            "Epoch 201/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3016 - mae: 1.4028 - val_loss: 3.7756 - val_mae: 1.3854\n",
            "Epoch 202/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7904 - mae: 1.2565 - val_loss: 3.1732 - val_mae: 1.3408\n",
            "Epoch 203/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3241 - mae: 1.3820 - val_loss: 3.3138 - val_mae: 1.3225\n",
            "Epoch 204/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4925 - mae: 1.2188 - val_loss: 3.1040 - val_mae: 1.3644\n",
            "Epoch 205/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7318 - mae: 1.3111 - val_loss: 3.1106 - val_mae: 1.3941\n",
            "Epoch 206/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7263 - mae: 1.3074 - val_loss: 3.7780 - val_mae: 1.3839\n",
            "Epoch 207/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.6621 - mae: 1.1897 - val_loss: 3.1125 - val_mae: 1.4465\n",
            "Epoch 208/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1028 - mae: 1.3968 - val_loss: 3.0560 - val_mae: 1.3910\n",
            "Epoch 209/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6966 - mae: 1.2946 - val_loss: 3.1899 - val_mae: 1.3233\n",
            "Epoch 210/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2650 - mae: 1.3884 - val_loss: 3.1137 - val_mae: 1.3277\n",
            "Epoch 211/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.0593 - mae: 1.3218 - val_loss: 3.0761 - val_mae: 1.3364\n",
            "Epoch 212/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6552 - mae: 1.2956 - val_loss: 3.0910 - val_mae: 1.3582\n",
            "Epoch 213/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7602 - mae: 1.3418 - val_loss: 3.1084 - val_mae: 1.3635\n",
            "Epoch 214/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3371 - mae: 1.3735 - val_loss: 3.1214 - val_mae: 1.3474\n",
            "Epoch 215/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5514 - mae: 1.2143 - val_loss: 3.2178 - val_mae: 1.3250\n",
            "Epoch 216/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7222 - mae: 1.2878 - val_loss: 3.1527 - val_mae: 1.4148\n",
            "Epoch 217/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8144 - mae: 1.2976 - val_loss: 3.4262 - val_mae: 1.3413\n",
            "Epoch 218/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3542 - mae: 1.1789 - val_loss: 3.1153 - val_mae: 1.4370\n",
            "Epoch 219/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9361 - mae: 1.3336 - val_loss: 3.4939 - val_mae: 1.3464\n",
            "Epoch 220/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7282 - mae: 1.2801 - val_loss: 3.4757 - val_mae: 1.3464\n",
            "Epoch 221/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9762 - mae: 1.3266 - val_loss: 3.8672 - val_mae: 1.3949\n",
            "Epoch 222/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.1831 - mae: 1.3362 - val_loss: 3.1882 - val_mae: 1.3196\n",
            "Epoch 223/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.5636 - mae: 1.2332 - val_loss: 3.3649 - val_mae: 1.3286\n",
            "Epoch 224/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2994 - mae: 1.2933 - val_loss: 3.6191 - val_mae: 1.3557\n",
            "Epoch 225/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5864 - mae: 1.2453 - val_loss: 3.2201 - val_mae: 1.3175\n",
            "Epoch 226/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4643 - mae: 1.2306 - val_loss: 3.1796 - val_mae: 1.4950\n",
            "Epoch 227/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8724 - mae: 1.3792 - val_loss: 3.1355 - val_mae: 1.4560\n",
            "Epoch 228/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6958 - mae: 1.3228 - val_loss: 3.2688 - val_mae: 1.3379\n",
            "Epoch 229/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9586 - mae: 1.2869 - val_loss: 3.2212 - val_mae: 1.3480\n",
            "Epoch 230/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8990 - mae: 1.3227 - val_loss: 3.1185 - val_mae: 1.3945\n",
            "Epoch 231/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.8268 - mae: 1.3422 - val_loss: 3.2023 - val_mae: 1.3243\n",
            "Epoch 232/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.6506 - mae: 1.2627 - val_loss: 3.0790 - val_mae: 1.3953\n",
            "Epoch 233/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3297 - mae: 1.3807 - val_loss: 3.1196 - val_mae: 1.3583\n",
            "Epoch 234/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2231 - mae: 1.3481 - val_loss: 3.1553 - val_mae: 1.3375\n",
            "Epoch 235/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6331 - mae: 1.2214 - val_loss: 3.3872 - val_mae: 1.3295\n",
            "Epoch 236/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9123 - mae: 1.2670 - val_loss: 3.5406 - val_mae: 1.3477\n",
            "Epoch 237/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.2340 - mae: 1.3815 - val_loss: 3.4756 - val_mae: 1.3458\n",
            "Epoch 238/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.5744 - mae: 1.1825 - val_loss: 3.3146 - val_mae: 1.3367\n",
            "Epoch 239/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9712 - mae: 1.3078 - val_loss: 3.5826 - val_mae: 1.3598\n",
            "Epoch 240/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7223 - mae: 1.2426 - val_loss: 3.2006 - val_mae: 1.3399\n",
            "Epoch 241/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5345 - mae: 1.2554 - val_loss: 3.2677 - val_mae: 1.3380\n",
            "Epoch 242/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9995 - mae: 1.2887 - val_loss: 3.3954 - val_mae: 1.3412\n",
            "Epoch 243/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8476 - mae: 1.2833 - val_loss: 3.1818 - val_mae: 1.3339\n",
            "Epoch 244/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2408 - mae: 1.3475 - val_loss: 3.1492 - val_mae: 1.4589\n",
            "Epoch 245/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8664 - mae: 1.3076 - val_loss: 3.1540 - val_mae: 1.3478\n",
            "Epoch 246/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.5343 - mae: 1.4375 - val_loss: 3.2222 - val_mae: 1.3167\n",
            "Epoch 247/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4169 - mae: 1.1871 - val_loss: 3.2690 - val_mae: 1.3266\n",
            "Epoch 248/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.3814 - mae: 1.2173 - val_loss: 3.2040 - val_mae: 1.3350\n",
            "Epoch 249/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.5176 - mae: 1.2415 - val_loss: 3.2919 - val_mae: 1.3347\n",
            "Epoch 250/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.8258 - mae: 1.3342 - val_loss: 3.1696 - val_mae: 1.3733\n",
            "Epoch 251/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.1194 - mae: 1.3589 - val_loss: 3.6717 - val_mae: 1.3723\n",
            "Epoch 252/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2757 - mae: 1.2844 - val_loss: 3.3277 - val_mae: 1.3326\n",
            "Epoch 253/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.7822 - mae: 1.2752 - val_loss: 3.3476 - val_mae: 1.3362\n",
            "Epoch 254/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8557 - mae: 1.3090 - val_loss: 3.2357 - val_mae: 1.3257\n",
            "Epoch 255/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.2723 - mae: 1.3328 - val_loss: 3.3339 - val_mae: 1.3288\n",
            "Epoch 256/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.6064 - mae: 1.2382 - val_loss: 3.1556 - val_mae: 1.3557\n",
            "Epoch 257/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1096 - mae: 1.3017 - val_loss: 3.1688 - val_mae: 1.3558\n",
            "Epoch 258/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8285 - mae: 1.3281 - val_loss: 3.6375 - val_mae: 1.3656\n",
            "Epoch 259/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5705 - mae: 1.2227 - val_loss: 3.1332 - val_mae: 1.3845\n",
            "Epoch 260/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9645 - mae: 1.3656 - val_loss: 3.6351 - val_mae: 1.3639\n",
            "Epoch 261/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.5019 - mae: 1.2365 - val_loss: 3.6187 - val_mae: 1.3631\n",
            "Epoch 262/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6495 - mae: 1.2832 - val_loss: 3.3754 - val_mae: 1.3390\n",
            "Epoch 263/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5696 - mae: 1.3006 - val_loss: 3.2481 - val_mae: 1.3372\n",
            "Epoch 264/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8397 - mae: 1.3122 - val_loss: 3.4183 - val_mae: 1.3446\n",
            "Epoch 265/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.0771 - mae: 1.3225 - val_loss: 3.7235 - val_mae: 1.3806\n",
            "Epoch 266/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.4348 - mae: 1.3198 - val_loss: 3.1326 - val_mae: 1.3812\n",
            "Epoch 267/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.7572 - mae: 1.3033 - val_loss: 3.2466 - val_mae: 1.3311\n",
            "Epoch 268/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.8479 - mae: 1.2638 - val_loss: 3.4815 - val_mae: 1.3523\n",
            "Epoch 269/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.6325 - mae: 1.2461 - val_loss: 3.3872 - val_mae: 1.3376\n",
            "Epoch 270/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.4654 - mae: 1.2131 - val_loss: 3.2507 - val_mae: 1.3258\n",
            "Epoch 271/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.9229 - mae: 1.2964 - val_loss: 3.4696 - val_mae: 1.3436\n",
            "Epoch 272/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.7279 - mae: 1.2960 - val_loss: 3.2224 - val_mae: 1.3184\n",
            "Epoch 273/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9791 - mae: 1.3289 - val_loss: 3.8930 - val_mae: 1.4025\n",
            "Epoch 274/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.1986 - mae: 1.2545 - val_loss: 3.2887 - val_mae: 1.3240\n",
            "Epoch 275/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8401 - mae: 1.2741 - val_loss: 3.2957 - val_mae: 1.3246\n",
            "Epoch 276/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8015 - mae: 1.2746 - val_loss: 3.1588 - val_mae: 1.3465\n",
            "Epoch 277/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.8338 - mae: 1.2826 - val_loss: 3.1195 - val_mae: 1.3794\n",
            "Epoch 278/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8474 - mae: 1.3376 - val_loss: 3.4326 - val_mae: 1.3420\n",
            "Epoch 279/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3054 - mae: 1.4089 - val_loss: 3.2034 - val_mae: 1.3374\n",
            "Epoch 280/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.2799 - mae: 1.4006 - val_loss: 3.2791 - val_mae: 1.3288\n",
            "Epoch 281/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3534 - mae: 1.3515 - val_loss: 3.2997 - val_mae: 1.3324\n",
            "Epoch 282/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6515 - mae: 1.2720 - val_loss: 3.3360 - val_mae: 1.3371\n",
            "Epoch 283/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5007 - mae: 1.1915 - val_loss: 3.1469 - val_mae: 1.3992\n",
            "Epoch 284/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2489 - mae: 1.3740 - val_loss: 3.5998 - val_mae: 1.3608\n",
            "Epoch 285/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.5192 - mae: 1.2252 - val_loss: 3.1374 - val_mae: 1.3892\n",
            "Epoch 286/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9095 - mae: 1.3259 - val_loss: 3.2399 - val_mae: 1.3328\n",
            "Epoch 287/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8145 - mae: 1.2584 - val_loss: 3.1846 - val_mae: 1.3513\n",
            "Epoch 288/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5389 - mae: 1.2583 - val_loss: 3.2169 - val_mae: 1.3455\n",
            "Epoch 289/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5793 - mae: 1.2402 - val_loss: 3.2505 - val_mae: 1.3558\n",
            "Epoch 290/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7529 - mae: 1.2831 - val_loss: 3.5582 - val_mae: 1.3587\n",
            "Epoch 291/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.2765 - mae: 1.1799 - val_loss: 3.3632 - val_mae: 1.3442\n",
            "Epoch 292/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.8067 - mae: 1.4766 - val_loss: 3.2653 - val_mae: 1.3406\n",
            "Epoch 293/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8683 - mae: 1.2506 - val_loss: 3.2965 - val_mae: 1.3359\n",
            "Epoch 294/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5240 - mae: 1.2350 - val_loss: 3.3783 - val_mae: 1.3405\n",
            "Epoch 295/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8096 - mae: 1.2519 - val_loss: 3.1216 - val_mae: 1.3580\n",
            "Epoch 296/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0628 - mae: 1.3318 - val_loss: 3.3767 - val_mae: 1.3343\n",
            "Epoch 297/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9003 - mae: 1.3001 - val_loss: 3.9210 - val_mae: 1.4064\n",
            "Epoch 298/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5959 - mae: 1.2060 - val_loss: 3.1644 - val_mae: 1.3398\n",
            "Epoch 299/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.1428 - mae: 1.3027 - val_loss: 3.5186 - val_mae: 1.3521\n",
            "Epoch 300/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8124 - mae: 1.2916 - val_loss: 3.2690 - val_mae: 1.3326\n",
            "Epoch 301/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7262 - mae: 1.2733 - val_loss: 3.3253 - val_mae: 1.3334\n",
            "Epoch 302/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.6181 - mae: 1.1907 - val_loss: 3.4231 - val_mae: 1.3417\n",
            "Epoch 303/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.1081 - mae: 1.3574 - val_loss: 3.7543 - val_mae: 1.3800\n",
            "Epoch 304/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.2813 - mae: 1.3949 - val_loss: 3.2353 - val_mae: 1.3204\n",
            "Epoch 305/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.0052 - mae: 1.3292 - val_loss: 3.2910 - val_mae: 1.3294\n",
            "Epoch 306/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5989 - mae: 1.2419 - val_loss: 3.5864 - val_mae: 1.3607\n",
            "Epoch 307/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7134 - mae: 1.2331 - val_loss: 3.4082 - val_mae: 1.3408\n",
            "Epoch 308/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5545 - mae: 1.2084 - val_loss: 3.1269 - val_mae: 1.3724\n",
            "Epoch 309/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.3743 - mae: 1.2094 - val_loss: 3.2180 - val_mae: 1.4840\n",
            "Epoch 310/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8665 - mae: 1.3563 - val_loss: 3.6894 - val_mae: 1.3768\n",
            "Epoch 311/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.8077 - mae: 1.2550 - val_loss: 3.2526 - val_mae: 1.3429\n",
            "Epoch 312/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8946 - mae: 1.3455 - val_loss: 3.1705 - val_mae: 1.3634\n",
            "Epoch 313/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.8486 - mae: 1.3186 - val_loss: 3.1917 - val_mae: 1.3495\n",
            "Epoch 314/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9073 - mae: 1.3034 - val_loss: 3.4167 - val_mae: 1.3419\n",
            "Epoch 315/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9116 - mae: 1.2701 - val_loss: 3.2163 - val_mae: 1.3316\n",
            "Epoch 316/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.4082 - mae: 1.1639 - val_loss: 3.1366 - val_mae: 1.3759\n",
            "Epoch 317/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5382 - mae: 1.2703 - val_loss: 3.1760 - val_mae: 1.4420\n",
            "Epoch 318/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0913 - mae: 1.3325 - val_loss: 3.4920 - val_mae: 1.3536\n",
            "Epoch 319/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0591 - mae: 1.3029 - val_loss: 3.1949 - val_mae: 1.3809\n",
            "Epoch 320/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.2652 - mae: 1.3553 - val_loss: 3.9701 - val_mae: 1.4195\n",
            "Epoch 321/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6899 - mae: 1.1842 - val_loss: 3.1904 - val_mae: 1.3649\n",
            "Epoch 322/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6779 - mae: 1.2577 - val_loss: 3.1681 - val_mae: 1.3627\n",
            "Epoch 323/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3100 - mae: 1.3812 - val_loss: 3.1600 - val_mae: 1.3809\n",
            "Epoch 324/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.5347 - mae: 1.2505 - val_loss: 3.2220 - val_mae: 1.3552\n",
            "Epoch 325/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 3.1565 - mae: 1.3060 - val_loss: 3.3138 - val_mae: 1.3343\n",
            "Epoch 326/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 3.1184 - mae: 1.3016 - val_loss: 3.3020 - val_mae: 1.3342\n",
            "Epoch 327/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.8203 - mae: 1.2938 - val_loss: 3.1981 - val_mae: 1.3425\n",
            "Epoch 328/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4957 - mae: 1.2519 - val_loss: 3.2990 - val_mae: 1.3376\n",
            "Epoch 329/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.8500 - mae: 1.2493 - val_loss: 3.1823 - val_mae: 1.4013\n",
            "Epoch 330/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 2.5736 - mae: 1.2447 - val_loss: 3.1776 - val_mae: 1.4157\n",
            "Epoch 331/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.9093 - mae: 1.3370 - val_loss: 3.5925 - val_mae: 1.3685\n",
            "Epoch 332/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.8773 - mae: 1.3020 - val_loss: 3.3716 - val_mae: 1.3433\n",
            "Epoch 333/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0916 - mae: 1.3457 - val_loss: 3.6904 - val_mae: 1.3782\n",
            "Epoch 334/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8886 - mae: 1.2733 - val_loss: 3.4300 - val_mae: 1.3495\n",
            "Epoch 335/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.1458 - mae: 1.2692 - val_loss: 3.1718 - val_mae: 1.3816\n",
            "Epoch 336/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.5028 - mae: 1.2298 - val_loss: 3.4691 - val_mae: 1.3536\n",
            "Epoch 337/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.8392 - mae: 1.2743 - val_loss: 3.3125 - val_mae: 1.3352\n",
            "Epoch 338/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.4174 - mae: 1.3924 - val_loss: 3.2144 - val_mae: 1.3455\n",
            "Epoch 339/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 3.2657 - mae: 1.3357 - val_loss: 3.5208 - val_mae: 1.3566\n",
            "Epoch 340/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.8516 - mae: 1.2922 - val_loss: 3.1731 - val_mae: 1.3523\n",
            "Epoch 341/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.9561 - mae: 1.3249 - val_loss: 3.1816 - val_mae: 1.3527\n",
            "Epoch 342/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.0017 - mae: 1.3291 - val_loss: 3.8724 - val_mae: 1.4029\n",
            "Epoch 343/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6520 - mae: 1.2357 - val_loss: 3.5695 - val_mae: 1.3567\n",
            "Epoch 344/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.9080 - mae: 1.3523 - val_loss: 3.4181 - val_mae: 1.3391\n",
            "Epoch 345/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6806 - mae: 1.2589 - val_loss: 3.2609 - val_mae: 1.3258\n",
            "Epoch 346/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6801 - mae: 1.2315 - val_loss: 3.3627 - val_mae: 1.3338\n",
            "Epoch 347/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1098 - mae: 1.3554 - val_loss: 3.8307 - val_mae: 1.3950\n",
            "Epoch 348/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9914 - mae: 1.3253 - val_loss: 3.4365 - val_mae: 1.3435\n",
            "Epoch 349/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5955 - mae: 1.2526 - val_loss: 3.6153 - val_mae: 1.3646\n",
            "Epoch 350/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2930 - mae: 1.3165 - val_loss: 3.2170 - val_mae: 1.3517\n",
            "Epoch 351/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6203 - mae: 1.2567 - val_loss: 3.4611 - val_mae: 1.3539\n",
            "Epoch 352/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7290 - mae: 1.2421 - val_loss: 3.1438 - val_mae: 1.3698\n",
            "Epoch 353/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.7990 - mae: 1.2533 - val_loss: 3.9301 - val_mae: 1.4137\n",
            "Epoch 354/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.5390 - mae: 1.1965 - val_loss: 3.1854 - val_mae: 1.4180\n",
            "Epoch 355/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.3867 - mae: 1.2386 - val_loss: 3.2438 - val_mae: 1.4752\n",
            "Epoch 356/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1668 - mae: 1.4084 - val_loss: 3.4506 - val_mae: 1.3537\n",
            "Epoch 357/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1806 - mae: 1.3662 - val_loss: 3.6506 - val_mae: 1.3726\n",
            "Epoch 358/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.2240 - mae: 1.0997 - val_loss: 3.1859 - val_mae: 1.4416\n",
            "Epoch 359/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1454 - mae: 1.3516 - val_loss: 3.2502 - val_mae: 1.3318\n",
            "Epoch 360/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0727 - mae: 1.3170 - val_loss: 3.3655 - val_mae: 1.3392\n",
            "Epoch 361/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.4660 - mae: 1.3729 - val_loss: 3.2240 - val_mae: 1.3232\n",
            "Epoch 362/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7352 - mae: 1.2447 - val_loss: 3.2198 - val_mae: 1.3306\n",
            "Epoch 363/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4891 - mae: 1.2128 - val_loss: 3.6264 - val_mae: 1.3687\n",
            "Epoch 364/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4881 - mae: 1.1807 - val_loss: 3.2525 - val_mae: 1.3283\n",
            "Epoch 365/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7232 - mae: 1.3318 - val_loss: 3.4740 - val_mae: 1.3509\n",
            "Epoch 366/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7382 - mae: 1.2682 - val_loss: 3.1524 - val_mae: 1.3764\n",
            "Epoch 367/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5815 - mae: 1.2562 - val_loss: 3.5262 - val_mae: 1.3594\n",
            "Epoch 368/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4571 - mae: 1.2266 - val_loss: 3.2590 - val_mae: 1.3600\n",
            "Epoch 369/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5699 - mae: 1.2544 - val_loss: 3.2743 - val_mae: 1.3705\n",
            "Epoch 370/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7538 - mae: 1.2466 - val_loss: 3.1917 - val_mae: 1.4273\n",
            "Epoch 371/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0428 - mae: 1.3413 - val_loss: 3.1736 - val_mae: 1.4001\n",
            "Epoch 372/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3539 - mae: 1.2025 - val_loss: 3.4650 - val_mae: 1.3572\n",
            "Epoch 373/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7733 - mae: 1.2667 - val_loss: 3.7918 - val_mae: 1.3920\n",
            "Epoch 374/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3361 - mae: 1.3877 - val_loss: 3.3075 - val_mae: 1.3295\n",
            "Epoch 375/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5257 - mae: 1.1898 - val_loss: 3.5042 - val_mae: 1.3504\n",
            "Epoch 376/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7449 - mae: 1.1888 - val_loss: 3.4923 - val_mae: 1.3507\n",
            "Epoch 377/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9487 - mae: 1.2929 - val_loss: 3.1113 - val_mae: 1.3705\n",
            "Epoch 378/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.5272 - mae: 1.2728 - val_loss: 3.3124 - val_mae: 1.3356\n",
            "Epoch 379/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4649 - mae: 1.2105 - val_loss: 3.2530 - val_mae: 1.3373\n",
            "Epoch 380/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9975 - mae: 1.2633 - val_loss: 3.1373 - val_mae: 1.4299\n",
            "Epoch 381/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9883 - mae: 1.3246 - val_loss: 3.5612 - val_mae: 1.3623\n",
            "Epoch 382/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.2327 - mae: 1.3134 - val_loss: 3.2238 - val_mae: 1.3291\n",
            "Epoch 383/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8486 - mae: 1.2966 - val_loss: 3.3048 - val_mae: 1.3312\n",
            "Epoch 384/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1662 - mae: 1.2985 - val_loss: 3.4034 - val_mae: 1.3419\n",
            "Epoch 385/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7411 - mae: 1.2448 - val_loss: 3.2479 - val_mae: 1.3293\n",
            "Epoch 386/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.0656 - mae: 1.2598 - val_loss: 3.2040 - val_mae: 1.3413\n",
            "Epoch 387/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3493 - mae: 1.2152 - val_loss: 3.2633 - val_mae: 1.5134\n",
            "Epoch 388/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.1667 - mae: 1.4089 - val_loss: 3.4805 - val_mae: 1.3504\n",
            "Epoch 389/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7784 - mae: 1.2979 - val_loss: 3.5471 - val_mae: 1.3637\n",
            "Epoch 390/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0663 - mae: 1.3193 - val_loss: 3.2528 - val_mae: 1.3363\n",
            "Epoch 391/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0792 - mae: 1.2710 - val_loss: 3.2194 - val_mae: 1.3683\n",
            "Epoch 392/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.2216 - mae: 1.3347 - val_loss: 3.2388 - val_mae: 1.3387\n",
            "Epoch 393/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6766 - mae: 1.2994 - val_loss: 3.2628 - val_mae: 1.3377\n",
            "Epoch 394/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3331 - mae: 1.3591 - val_loss: 3.3673 - val_mae: 1.3407\n",
            "Epoch 395/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.7060 - mae: 1.2628 - val_loss: 3.3090 - val_mae: 1.3369\n",
            "Epoch 396/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2702 - mae: 1.3316 - val_loss: 3.1580 - val_mae: 1.3808\n",
            "Epoch 397/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2099 - mae: 1.3312 - val_loss: 3.1499 - val_mae: 1.3714\n",
            "Epoch 398/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5480 - mae: 1.2724 - val_loss: 3.1963 - val_mae: 1.4003\n",
            "Epoch 399/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6809 - mae: 1.3264 - val_loss: 3.2817 - val_mae: 1.3706\n",
            "Epoch 400/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7063 - mae: 1.2501 - val_loss: 3.2467 - val_mae: 1.4744\n",
            "Epoch 401/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6409 - mae: 1.2950 - val_loss: 3.2483 - val_mae: 1.4720\n",
            "Epoch 402/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7686 - mae: 1.2789 - val_loss: 3.2026 - val_mae: 1.3788\n",
            "Epoch 403/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.6097 - mae: 1.2798 - val_loss: 3.2061 - val_mae: 1.4374\n",
            "Epoch 404/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7968 - mae: 1.3205 - val_loss: 3.6658 - val_mae: 1.3741\n",
            "Epoch 405/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9497 - mae: 1.2814 - val_loss: 3.9318 - val_mae: 1.4133\n",
            "Epoch 406/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.2658 - mae: 1.3722 - val_loss: 3.2555 - val_mae: 1.3288\n",
            "Epoch 407/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0610 - mae: 1.2983 - val_loss: 3.1302 - val_mae: 1.3500\n",
            "Epoch 408/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7574 - mae: 1.2854 - val_loss: 3.1775 - val_mae: 1.3518\n",
            "Epoch 409/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9357 - mae: 1.2774 - val_loss: 3.2046 - val_mae: 1.3415\n",
            "Epoch 410/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8286 - mae: 1.2874 - val_loss: 3.2418 - val_mae: 1.3319\n",
            "Epoch 411/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.3576 - mae: 1.1763 - val_loss: 3.2727 - val_mae: 1.3439\n",
            "Epoch 412/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2669 - mae: 1.3440 - val_loss: 3.6177 - val_mae: 1.3710\n",
            "Epoch 413/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.6325 - mae: 1.4155 - val_loss: 3.3139 - val_mae: 1.3374\n",
            "Epoch 414/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8035 - mae: 1.3154 - val_loss: 3.1957 - val_mae: 1.3431\n",
            "Epoch 415/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4592 - mae: 1.2233 - val_loss: 3.1388 - val_mae: 1.3934\n",
            "Epoch 416/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6133 - mae: 1.1997 - val_loss: 3.3467 - val_mae: 1.3380\n",
            "Epoch 417/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3754 - mae: 1.3523 - val_loss: 3.3287 - val_mae: 1.3353\n",
            "Epoch 418/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.1191 - mae: 1.2960 - val_loss: 3.3642 - val_mae: 1.3378\n",
            "Epoch 419/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.4791 - mae: 1.2088 - val_loss: 3.1831 - val_mae: 1.3851\n",
            "Epoch 420/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.6311 - mae: 1.2738 - val_loss: 3.6339 - val_mae: 1.3731\n",
            "Epoch 421/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8921 - mae: 1.2744 - val_loss: 3.5615 - val_mae: 1.3631\n",
            "Epoch 422/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0072 - mae: 1.2267 - val_loss: 3.4544 - val_mae: 1.3533\n",
            "Epoch 423/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.3137 - mae: 1.3236 - val_loss: 3.5400 - val_mae: 1.3560\n",
            "Epoch 424/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5766 - mae: 1.2659 - val_loss: 3.2286 - val_mae: 1.3339\n",
            "Epoch 425/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.8086 - mae: 1.2922 - val_loss: 3.3566 - val_mae: 1.3395\n",
            "Epoch 426/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.7040 - mae: 1.2887 - val_loss: 3.2935 - val_mae: 1.3406\n",
            "Epoch 427/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.0447 - mae: 1.0897 - val_loss: 3.2670 - val_mae: 1.3505\n",
            "Epoch 428/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5356 - mae: 1.2354 - val_loss: 3.2091 - val_mae: 1.3564\n",
            "Epoch 429/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.1887 - mae: 1.3206 - val_loss: 3.6707 - val_mae: 1.3732\n",
            "Epoch 430/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.6264 - mae: 1.1876 - val_loss: 3.2536 - val_mae: 1.3446\n",
            "Epoch 431/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.8375 - mae: 1.3243 - val_loss: 3.1687 - val_mae: 1.4397\n",
            "Epoch 432/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8579 - mae: 1.3082 - val_loss: 3.9923 - val_mae: 1.4205\n",
            "Epoch 433/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7318 - mae: 1.2451 - val_loss: 3.6175 - val_mae: 1.3666\n",
            "Epoch 434/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.0255 - mae: 1.3211 - val_loss: 3.5096 - val_mae: 1.3556\n",
            "Epoch 435/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5522 - mae: 1.2375 - val_loss: 3.4324 - val_mae: 1.3516\n",
            "Epoch 436/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7057 - mae: 1.2893 - val_loss: 3.3740 - val_mae: 1.3454\n",
            "Epoch 437/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.1875 - mae: 1.2887 - val_loss: 3.4009 - val_mae: 1.3492\n",
            "Epoch 438/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8913 - mae: 1.2918 - val_loss: 3.5809 - val_mae: 1.3701\n",
            "Epoch 439/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7203 - mae: 1.2655 - val_loss: 3.2589 - val_mae: 1.3445\n",
            "Epoch 440/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3572 - mae: 1.2128 - val_loss: 3.3586 - val_mae: 1.3469\n",
            "Epoch 441/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4168 - mae: 1.1894 - val_loss: 3.3245 - val_mae: 1.3440\n",
            "Epoch 442/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7751 - mae: 1.3189 - val_loss: 3.2830 - val_mae: 1.3535\n",
            "Epoch 443/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4780 - mae: 1.2403 - val_loss: 3.3599 - val_mae: 1.3511\n",
            "Epoch 444/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3584 - mae: 1.3602 - val_loss: 3.1968 - val_mae: 1.3871\n",
            "Epoch 445/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1334 - mae: 1.3659 - val_loss: 3.2861 - val_mae: 1.3600\n",
            "Epoch 446/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2557 - mae: 1.3349 - val_loss: 3.3203 - val_mae: 1.3496\n",
            "Epoch 447/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.9914 - mae: 1.3145 - val_loss: 3.7121 - val_mae: 1.3874\n",
            "Epoch 448/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8952 - mae: 1.2934 - val_loss: 3.5630 - val_mae: 1.3701\n",
            "Epoch 449/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3277 - mae: 1.3350 - val_loss: 3.5218 - val_mae: 1.3638\n",
            "Epoch 450/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9884 - mae: 1.2956 - val_loss: 3.3930 - val_mae: 1.3518\n",
            "Epoch 451/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5695 - mae: 1.2389 - val_loss: 3.2760 - val_mae: 1.3384\n",
            "Epoch 452/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.3834 - mae: 1.1765 - val_loss: 3.1976 - val_mae: 1.3422\n",
            "Epoch 453/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6126 - mae: 1.2400 - val_loss: 3.1798 - val_mae: 1.3860\n",
            "Epoch 454/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5928 - mae: 1.2908 - val_loss: 3.2458 - val_mae: 1.3645\n",
            "Epoch 455/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9098 - mae: 1.3232 - val_loss: 4.0940 - val_mae: 1.4378\n",
            "Epoch 456/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7701 - mae: 1.2347 - val_loss: 3.2815 - val_mae: 1.3453\n",
            "Epoch 457/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6101 - mae: 1.2360 - val_loss: 3.4531 - val_mae: 1.3606\n",
            "Epoch 458/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3345 - mae: 1.3649 - val_loss: 3.2661 - val_mae: 1.3601\n",
            "Epoch 459/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.2357 - mae: 1.3674 - val_loss: 3.2950 - val_mae: 1.3429\n",
            "Epoch 460/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0783 - mae: 1.2801 - val_loss: 3.1996 - val_mae: 1.4521\n",
            "Epoch 461/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0143 - mae: 1.3601 - val_loss: 3.2732 - val_mae: 1.3682\n",
            "Epoch 462/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.5219 - mae: 1.2384 - val_loss: 3.2905 - val_mae: 1.3589\n",
            "Epoch 463/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.9376 - mae: 1.3231 - val_loss: 3.2392 - val_mae: 1.3456\n",
            "Epoch 464/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6697 - mae: 1.3022 - val_loss: 3.2193 - val_mae: 1.3615\n",
            "Epoch 465/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7017 - mae: 1.2755 - val_loss: 3.6137 - val_mae: 1.3729\n",
            "Epoch 466/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0873 - mae: 1.1047 - val_loss: 3.2074 - val_mae: 1.3803\n",
            "Epoch 467/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9248 - mae: 1.3200 - val_loss: 3.4771 - val_mae: 1.3578\n",
            "Epoch 468/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9204 - mae: 1.2528 - val_loss: 3.3515 - val_mae: 1.3424\n",
            "Epoch 469/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8702 - mae: 1.2826 - val_loss: 3.4206 - val_mae: 1.3491\n",
            "Epoch 470/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.6103 - mae: 1.2678 - val_loss: 3.2592 - val_mae: 1.3465\n",
            "Epoch 471/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.1823 - mae: 1.3086 - val_loss: 3.3915 - val_mae: 1.3446\n",
            "Epoch 472/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6008 - mae: 1.2472 - val_loss: 3.3619 - val_mae: 1.3434\n",
            "Epoch 473/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.0101 - mae: 1.3231 - val_loss: 3.6626 - val_mae: 1.3714\n",
            "Epoch 474/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5371 - mae: 1.1907 - val_loss: 3.4026 - val_mae: 1.3481\n",
            "Epoch 475/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4930 - mae: 1.1958 - val_loss: 3.2014 - val_mae: 1.3637\n",
            "Epoch 476/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7655 - mae: 1.3028 - val_loss: 3.5646 - val_mae: 1.3645\n",
            "Epoch 477/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7616 - mae: 1.2951 - val_loss: 3.4711 - val_mae: 1.3513\n",
            "Epoch 478/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2944 - mae: 1.3447 - val_loss: 3.2294 - val_mae: 1.3417\n",
            "Epoch 479/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0128 - mae: 1.3250 - val_loss: 3.1566 - val_mae: 1.4332\n",
            "Epoch 480/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.9617 - mae: 1.3703 - val_loss: 3.2840 - val_mae: 1.3552\n",
            "Epoch 481/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6018 - mae: 1.2471 - val_loss: 3.9023 - val_mae: 1.4086\n",
            "Epoch 482/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3141 - mae: 1.1462 - val_loss: 3.2078 - val_mae: 1.3867\n",
            "Epoch 483/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6358 - mae: 1.2985 - val_loss: 3.3345 - val_mae: 1.3413\n",
            "Epoch 484/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2168 - mae: 1.3106 - val_loss: 3.3745 - val_mae: 1.3446\n",
            "Epoch 485/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5098 - mae: 1.2385 - val_loss: 3.7659 - val_mae: 1.3886\n",
            "Epoch 486/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.2207 - mae: 1.2609 - val_loss: 3.4467 - val_mae: 1.3521\n",
            "Epoch 487/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.1178 - mae: 1.2838 - val_loss: 3.1370 - val_mae: 1.3933\n",
            "Epoch 488/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.3090 - mae: 1.3762 - val_loss: 3.2031 - val_mae: 1.3486\n",
            "Epoch 489/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5169 - mae: 1.2458 - val_loss: 3.2295 - val_mae: 1.3539\n",
            "Epoch 490/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1416 - mae: 1.3169 - val_loss: 3.2435 - val_mae: 1.3412\n",
            "Epoch 491/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0566 - mae: 1.2917 - val_loss: 3.2959 - val_mae: 1.3351\n",
            "Epoch 492/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3036 - mae: 1.3492 - val_loss: 3.2597 - val_mae: 1.3324\n",
            "Epoch 493/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1784 - mae: 1.3024 - val_loss: 3.4624 - val_mae: 1.3515\n",
            "Epoch 494/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6008 - mae: 1.2278 - val_loss: 3.2262 - val_mae: 1.3401\n",
            "Epoch 495/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8087 - mae: 1.2582 - val_loss: 3.1096 - val_mae: 1.4114\n",
            "Epoch 496/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7708 - mae: 1.2480 - val_loss: 3.2293 - val_mae: 1.3282\n",
            "Epoch 497/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.0225 - mae: 1.2564 - val_loss: 3.8923 - val_mae: 1.4032\n",
            "Epoch 498/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3746 - mae: 1.1895 - val_loss: 3.2152 - val_mae: 1.3442\n",
            "Epoch 499/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3826 - mae: 1.3706 - val_loss: 3.2509 - val_mae: 1.3495\n",
            "Epoch 500/500\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9946 - mae: 1.3207 - val_loss: 3.4763 - val_mae: 1.3582\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x781ab77aee90>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(xtrain,ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADwT7P5wB-88",
        "outputId": "7d4bc778-f4d6-4427-9027-8b3d405e0d95"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.2376 - mae: 1.3230 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.7638943195343018, 1.2407909631729126]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(xtest,ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJEWcobNCD8O",
        "outputId": "9ed7237d-292d-4917-f89c-ebc84b0a1d90"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.2187 - mae: 1.3094\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.476271629333496, 1.3582205772399902]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vE99KWfmDAVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}